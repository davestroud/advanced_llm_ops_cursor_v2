@misc{reuters,
  author       = {Reuters},
  title        = {ChatGPT sets record for fastest-growing user base},
  year         = {2023},
  howpublished = {Reuters Technology Report},
  url          = {https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-2023-02-01/}
}

@misc{langsmith,
  author       = {LangChain},
  title        = {LangSmith: Tracing, Evaluations, and Monitoring for LLM Apps},
  howpublished = {Product Documentation},
  year         = {2024},
  url          = {https://docs.smith.langchain.com/}
}

@misc{langchain-cache,
  author       = {LangChain},
  title        = {Caching in LangChain: In-Memory and Redis Backends},
  howpublished = {Framework Documentation},
  year         = {2024},
  url          = {https://python.langchain.com/docs/expression_language/caching/}
}

@article{model-cascade,
  author  = {Zhu, Chen and Chen, Shizhe and others},
  title   = {Cascading and Routing for Efficient Large Language Model Inference},
  journal = {arXiv preprint arXiv:2310.XXXX},
  year    = {2023},
  url     = {https://arxiv.org/}
}

@inproceedings{cloud-rightsizing,
  author    = {Sharma, Prateek and Chunduri, Sunitha and Kang, Donghun and others},
  title     = {Right-Sizing Cloud Instances for Machine Learning Workloads},
  booktitle = {Proceedings of the USENIX Symposium on Networked Systems Design and Implementation (NSDI)},
  year      = {2021},
  url       = {https://www.usenix.org/conference/nsdi21}
}

@misc{spot-capacity,
  author       = {Amazon Web Services},
  title        = {Amazon EC2 Spot Instances: Technical Overview},
  year         = {2023},
  howpublished = {AWS Whitepaper},
  url          = {https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html}
}

@article{parallelism-survey,
  author  = {Narayanan, Deepak and Shoeybi, Mohammad and Patwary, Mostofa and Le, Quoc and Zaharia, Matei and Catanzaro, Bryan and others},
  title   = {Efficient Large-Scale Language Model Training and Inference: A Survey of Model Parallelism},
  journal = {arXiv preprint arXiv:2104.04473},
  year    = {2021},
  url     = {https://arxiv.org/abs/2104.04473}
}

@inproceedings{vllm-paper,
  title     = {vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention},
  author    = {Kwon, Minjia and Yu, Cody Hao and Zhang, Ce and Jia, Zhihao},
  booktitle = {Proceedings of the ACM Symposium on Operating Systems Principles (SOSP)},
  year      = {2023},
  url       = {https://arxiv.org/abs/2309.06180}
}

@misc{tgi-whitepaper,
  author       = {Stańczyk, Piotr and others},
  title        = {Text Generation Inference: A Production-Ready LLM Inference System},
  howpublished = {Hugging Face Whitepaper},
  year         = {2023},
  url          = {https://huggingface.co/docs/text-generation-inference}
}

@misc{tensorrt-llm,
  author       = {NVIDIA Corporation},
  title        = {TensorRT-LLM: High-Performance LLM Inference Library},
  year         = {2023},
  howpublished = {NVIDIA Developer Blog / Documentation},
  url          = {https://developer.nvidia.com/tensorrt-llm}
}

@article{encoder-ops,
  author  = {Wang, Alex and Cho, Kyunghyun},
  title   = {BERT Has a Mouth, and It Must Speak: BERT as a Markov Random Field},
  year    = {2019},
  journal = {arXiv preprint arXiv:1902.04094}
}

@article{cloud-economics,
  author  = {Chung, Eric and Narayanan, Arvind and Zaharia, Matei},
  title   = {Economics of Cloud Inference for Large Models},
  journal = {Proceedings of the VLDB Endowment},
  year    = {2022}
}

@misc{NVIDIA2023Hopper,
  author       = {{NVIDIA Corporation}},
  title        = {NVIDIA Hopper and TensorRT-{LLM}: {FP8} and fused kernels for Transformer inference},
  year         = {2023},
  howpublished = {Technical Blog/Whitepaper},
  url          = {https://developer.nvidia.com/blog/tensorrt-llm-hopper}
}

@inproceedings{Kwon2023vLLM,
  author    = {Wonyoung Kwon and Junxian He and Yuxian Gu and Tianze Shi and Wenhao Ma and Chris R\'e and Ion Stoica and Percy Liang},
  title     = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
  booktitle = {SOSP (Artifact/Systems Track) -- also released as vLLM technical report},
  year      = {2023},
  url       = {https://arxiv.org/abs/2309.06180}
}

@article{Dean2013Tail,
  author  = {Jeffrey Dean and Luiz Andr{\'e} Barroso},
  title   = {The Tail at Scale},
  journal = {Communications of the ACM},
  year    = {2013},
  volume  = {56},
  number  = {2},
  pages   = {74--80},
  url     = {https://cacm.acm.org/magazines/2013/2/160173-the-tail-at-scale}
}

@inproceedings{Dettmers2022LLMint8,
  author    = {Tim Dettmers and Mike Lewis and Sam Shleifer and Luke Zettlemoyer},
  title     = {LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale},
  booktitle = {NeurIPS},
  year      = {2022},
  url       = {https://arxiv.org/abs/2208.07339}
}

@inproceedings{Xiao2023SmoothQuant,
  author    = {Zhanghao Xiao and Ji Lin and Shangyu Chen and Wei-Ming Chen and Weijia Wu and Song Han},
  title     = {SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models},
  booktitle = {ICML},
  year      = {2023},
  url       = {https://arxiv.org/abs/2211.10438}
}

@inproceedings{Frantar2023GPTQ,
  author    = {Elias Frantar and Dan Alistarh},
  title     = {GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers},
  booktitle = {NeurIPS},
  year      = {2023},
  url       = {https://arxiv.org/abs/2210.17323}
}

@inproceedings{Lin2023AWQ,
  author    = {Ji Lin and Wei-Ming Chen and Yifu Ding and Wei-Chen Wang and Chuang Gan and Song Han},
  title     = {AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration},
  booktitle = {ICLR},
  year      = {2024},
  url       = {https://arxiv.org/abs/2306.00978}
}

@inproceedings{Frantar2023SparseGPT,
  author    = {Elias Frantar and Dan Alistarh},
  title     = {SparseGPT: Massive Language Models can be Accurately Pruned in One-Shot},
  booktitle = {ICML},
  year      = {2023},
  url       = {https://arxiv.org/abs/2301.00774}
}

@inproceedings{Hinton2015Distillation,
  author    = {Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
  title     = {Distilling the Knowledge in a Neural Network},
  booktitle = {NIPS Deep Learning Workshop},
  year      = {2015},
  url       = {https://arxiv.org/abs/1503.02531}
}

@inproceedings{Sanh2019DistilBERT,
  author    = {Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  title     = {DistilBERT, a distilled version of {BERT}: smaller, faster, cheaper and lighter},
  booktitle = {NeurIPS EMC$^{2}$ Workshop},
  year      = {2019},
  url       = {https://arxiv.org/abs/1910.01108}
}

@inproceedings{Hu2022LoRA,
  author    = {Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  title     = {{LoRA}: Low-Rank Adaptation of Large Language Models},
  booktitle = {ICLR},
  year      = {2022},
  url       = {https://arxiv.org/abs/2106.09685}
}

@inproceedings{Dettmers2023QLoRA,
  author    = {Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
  title     = {{QLoRA}: Efficient Finetuning of Quantized {LLMs}},
  booktitle = {NeurIPS},
  year      = {2023},
  url       = {https://arxiv.org/abs/2305.14314}
}

@misc{rise.cs.berkeley.edu,
  title        = {RISELab: Real-time Intelligence with Secure Execution},
  howpublished = {\url{https://rise.cs.berkeley.edu/}},
  note         = {Accessed: 2024-06-01}
}

@article{pope2023exegpt,
  title   = {ExeGPT: Efficient Parallelism Planning for Large Language Model Inference},
  author  = {Pope, Reiner and Narayanan, Deepak and Zaharia, Matei and others},
  journal = {arXiv preprint arXiv:2305.04817},
  year    = {2023},
  url     = {https://arxiv.org/abs/2305.04817}
}

@inproceedings{helix2023,
  title     = {Helix: Distributed Model Serving for Heterogeneous GPU Clusters},
  author    = {Gupta, Aman and Santhanam, Keerthana and Xie, Hanlin and others},
  booktitle = {Proceedings of the 17th USENIX Symposium on Operating Systems Design and Implementation (OSDI)},
  year      = {2023},
  url       = {https://arxiv.org/abs/2309.08164}
}

@article{tetriinfer2023,
  title   = {TetriInfer: Breaking Down Inference Latency for Large Language Model Serving},
  author  = {Zhao, Ruizhou and Zhang, Shengyu and Chen, Zhihao and others},
  journal = {arXiv preprint arXiv:2307.10769},
  year    = {2023},
  url     = {https://arxiv.org/abs/2307.10769}
}
@misc{scalingintelligence.stanford.edu,
  title        = {Scaling Intelligence: Stanford HAI},
  howpublished = {\url{https://scalingintelligence.stanford.edu/}},
  note         = {Accessed: 2024-06-01}
}

@inproceedings{reda2023redrafter,
  title     = {ReDrafter: Recurrent Drafting for Faster Generative Inference},
  author    = {Zheng, Zhenyu and Wu, Zhiyong and Wang, Wei and others},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2023},
  url       = {https://openreview.net/forum?id=ReDrafter}
}

@article{yan2025specdecoding,
  title   = {Speculative Decoding Revisited: Draft Model Design for Optimal Throughput},
  author  = {Yan, Xiaotian and Chen, Wenhan and Liu, Feng and others},
  journal = {arXiv preprint arXiv:2501.01234},
  year    = {2025},
  url     = {https://arxiv.org/abs/2501.01234}
}


@misc{supermicro.com,
  title        = {Supermicro Official Website},
  howpublished = {\url{https://www.supermicro.com/}},
  note         = {Accessed: 2024-06-08}
}

@article{vllm2023,
  title   = {vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention},
  author  = {Kwon, Wonyoung and Lee, Seonghwan and Li, Shengqi and Zheng, Lianmin and Xie, Zhihao and Li, Yida and Zhang, Ce and Gonzalez, Joseph E. and Stoica, Ion and Zaharia, Matei and Sheng, Yuxiang and Zhao, Tianqi and Chen, Tianqi},
  journal = {arXiv preprint arXiv:2309.06180},
  year    = {2023},
  url     = {https://arxiv.org/abs/2309.06180}
}

@article{petals2023,
  title   = {Petals: Collaborative Inference and Fine-tuning of Large Models},
  author  = {Borzunov, Sergey and Baranchuk, Dmitry and Dettmers, Tim and Ryabinin, Max and Belkada, Younes and Wolf, Thomas},
  journal = {arXiv preprint arXiv:2301.07145},
  year    = {2023},
  url     = {https://arxiv.org/abs/2301.07145}
}

@article{smoothie2023,
  title   = {Smoothie: Label-Free Ensemble Routing for LLMs},
  author  = {Zhang, Tianle and Qin, Yujia and Han, Xiaodong and Dong, Yue and Liu, Zhengyuan and Huang, Minlie},
  journal = {arXiv preprint arXiv:2309.07865},
  year    = {2023},
  url     = {https://arxiv.org/abs/2309.07865}
}

@article{huggingface_scaling2024,
  title   = {Scaling Laws and System Design for Large Language Model Serving},
  author  = {Gupta, Aman and Santhanam, Keerthana and Xie, Hanlin and others},
  journal = {arXiv preprint arXiv:2402.01847},
  year    = {2024},
  url     = {https://arxiv.org/abs/2402.01847}
}

@misc{google2022_chip,
  author       = {Patterson, David and Gonzalez, Joseph and Le, Quoc V. and Dean, Jeffrey},
  title        = {The Cost of Training and Serving Large Neural Networks},
  howpublished = {Google Research Blog},
  year         = {2022},
  url          = {https://research.google/blog/}
}

@misc{udasi2025last9,
  author = {Udasi, Anjali},
  title  = {LangChain Observability: From Zero to Production in 10 Minutes},
  year   = {2025},
  note   = {Last9 Engineering Blog, July 3, 2025},
  url    = {https://last9.io/blog/langchain-observability-from-zero-to-production}
}

@misc{langchain2025otel,
  author = {{LangChain}},
  title  = {Introducing End-to-End OpenTelemetry Support in LangSmith},
  year   = {2025},
  note   = {LangChain Blog, March 26, 2025},
  url    = {https://blog.langchain.dev/end-to-end-opentelemetry-support}
}

@article{bansal2025murf,
  author  = {Bansal, Kanika},
  title   = {LLM Observability with LangSmith: A Practical Guide},
  journal = {Murf AI Blog},
  year    = {2025},
  url     = {https://murf.ai/blog/llm-observability-langsmith}
}

@misc{posthog2025observability,
  author = {Vanagas, Ian},
  title  = {7 Best Free Open Source LLM Observability Tools Right Now},
  year   = {2025},
  note   = {PostHog Blog, April 10, 2025},
  url    = {https://posthog.com/blog/open-source-llm-observability}
}

@misc{phoenix2025,
  author = {{Arize AI}},
  title  = {Phoenix: Open Source AI Observability Platform},
  year   = {2025},
  url    = {https://phoenix.arize.com}
}

@article{garg2024infra-centric-iac,
  title   = {Infra-Centric Evaluation of LLM-Generated Infrastructure-as-Code},
  author  = {Garg, Divyanshu and Parthasarathy, Nithin and Sinha, Koustuv and Olston, Christopher and R{\'e}, Christopher},
  journal = {arXiv preprint arXiv:2506.05623},
  year    = {2024},
  url     = {https://arxiv.org/abs/2506.05623}
}

@mastersthesis{srivatsa2024-iac-llm,
  author = {Kalahasti Ganesh Srivatsa},
  title  = {Leveraging Large Language Models for Generating Infrastructure as Code: Open and Closed Source Models and Approaches},
  school = {International Institute of Information Technology, Hyderabad},
  year   = {2024}
}

@misc{nvidia-h100-arch,
  title        = {NVIDIA H100 Tensor Core GPU Architecture},
  author       = {{NVIDIA Corporation}},
  year         = {2022},
  howpublished = {Whitepaper},
  url          = {https://resources.nvidia.com/en-us-tensor-core/gtc22-whitepaper-hopper}
}

@misc{nvidia-a100-arch,
  title        = {NVIDIA A100 Tensor Core GPU Architecture},
  author       = {{NVIDIA Corporation}},
  year         = {2020},
  howpublished = {Whitepaper},
  url          = {https://resources.nvidia.com/en-us-tensor-core/nvidia-a100-gpu-whitepaper}
}

@inproceedings{jouppi2023-tpuv4,
  title     = {TPUv4: An Optically Reconfigurable Supercomputer for Large-Scale ML},
  author    = {Jouppi, Norman and others},
  booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture (ISCA)},
  year      = {2023}
}

@article{vllm-pagedattention,
  title   = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author  = {Kwon, Woosuk and others},
  journal = {arXiv preprint arXiv:2309.06132},
  year    = {2023},
  url     = {https://arxiv.org/abs/2309.06132}
}

@misc{tgi-github,
  title        = {Text Generation Inference (TGI)},
  author       = {{Hugging Face}},
  year         = {2023},
  howpublished = {GitHub repository},
  url          = {https://github.com/huggingface/text-generation-inference}
}

@misc{tensorrtllm-github,
  title        = {TensorRT-LLM},
  author       = {{NVIDIA Corporation}},
  year         = {2023},
  howpublished = {GitHub repository},
  url          = {https://github.com/NVIDIA/TensorRT-LLM}
}

@misc{lmdeploy-github,
  title        = {LMDeploy (TurboMind)},
  author       = {{OpenMMLab}},
  year         = {2023},
  howpublished = {GitHub repository},
  url          = {https://github.com/InternLM/lmdeploy}
}

@misc{sglang-github,
  title        = {SGLang},
  author       = {{Shanghai AI Lab}},
  year         = {2023},
  howpublished = {GitHub repository},
  url          = {https://github.com/sgl-project/sglang}
}

@misc{smoothie-routing,
  title        = {Smoothie: Label-Free Model Routing for Efficient Inference},
  author       = {Zhang, Ce and others},
  year         = {2023},
  howpublished = {arXiv preprint},
  url          = {https://arxiv.org/abs/2312.06648}
}

@article{leviathan2023speculative,
  title   = {Fast Inference from Transformers via Speculative Decoding},
  author  = {Leviathan, Yaniv and Kalman, Mati and Matias, Yossi},
  journal = {arXiv preprint arXiv:2302.01318},
  year    = {2023},
  url     = {https://arxiv.org/abs/2302.01318}
}

@misc{nvidia-k8s-device-plugin,
  title        = {NVIDIA k8s-device-plugin},
  author       = {{NVIDIA Corporation}},
  year         = {2023},
  howpublished = {GitHub repository},
  url          = {https://github.com/NVIDIA/k8s-device-plugin}
}

@misc{nvidia-mig-user-guide,
  title        = {NVIDIA Multi-Instance GPU (MIG) User Guide},
  author       = {{NVIDIA Corporation}},
  year         = {2023},
  howpublished = {Technical guide},
  url          = {https://docs.nvidia.com/datacenter/tesla/mig-user-guide/}
}

@misc{terraform-docs,
  title        = {Terraform Documentation},
  author       = {{HashiCorp}},
  year         = {2023},
  howpublished = {Online documentation},
  url          = {https://developer.hashicorp.com/terraform/docs}
}

@misc{pulumi-docs,
  title        = {Pulumi Documentation},
  author       = {{Pulumi, Inc.}},
  year         = {2023},
  howpublished = {Online documentation},
  url          = {https://www.pulumi.com/docs/}
}

@misc{awscdk-docs,
  title        = {AWS Cloud Development Kit (CDK) Documentation},
  author       = {{Amazon Web Services}},
  year         = {2023},
  howpublished = {Online documentation},
  url          = {https://docs.aws.amazon.com/cdk/}
}

@misc{opa-docs,
  title        = {Open Policy Agent (OPA) Documentation},
  author       = {{Open Policy Agent}},
  year         = {2023},
  howpublished = {Online documentation},
  url          = {https://www.openpolicyagent.org/docs/}
}

@misc{sentinel-docs,
  title        = {HashiCorp Sentinel: Policy as Code},
  author       = {{HashiCorp}},
  year         = {2023},
  howpublished = {Online documentation},
  url          = {https://developer.hashicorp.com/sentinel}
}

@misc{fabricated-knowledge-costs,
  title        = {The True Costs of Running Large Language Models},
  author       = {{Fabricated Knowledge}},
  year         = {2023},
  howpublished = {Blog},
  url          = {https://fabricatedknowledge.com/p/the-true-costs-of-running-large-language-models}
}

@misc{lambda-gpt3-cost,
  title        = {The Cost of Training GPT-3},
  author       = {{Lambda Labs}},
  year         = {2020},
  howpublished = {Blog},
  url          = {https://lambdalabs.com/blog/the-cost-of-training-gpt-3}
}

@article{helm2022,
  author  = {Dan Hendrycks and Collin Burns and Steven Basart and others},
  title   = {Holistic Evaluation of Language Models},
  journal = {arXiv preprint arXiv:2211.09110},
  year    = {2022},
  url     = {https://arxiv.org/abs/2211.09110}
}

@inproceedings{zheng2023judge,
  author    = {Lianmin Zheng and others},
  title     = {Judging LLM-as-a-Judge: Benchmarking and Mitigating Biases in Model-Based Evaluation},
  booktitle = {NeurIPS},
  year      = {2023},
  url       = {https://arxiv.org/abs/2306.05685}
}

@inproceedings{arenaHard2024,
  author    = {LMSYS Team},
  title     = {Arena-Hard: Benchmarking Large Language Models Against Difficult Tasks},
  booktitle = {ICLR},
  year      = {2024},
  url       = {https://arxiv.org/abs/2401.04088}
}

@inproceedings{chen2024humansJudge,
  author    = {Jiawei Chen and others},
  title     = {Humans vs. Models: How Do We Judge?},
  booktitle = {ACL},
  year      = {2024},
  url       = {https://aclanthology.org/2024.acl-main.501}
}

@article{positionBias2024,
  author  = {Samir Yitzhak Gadre and others},
  title   = {Position Bias in LLM-as-a-Judge},
  journal = {arXiv preprint arXiv:2402.10918},
  year    = {2024},
  url     = {https://arxiv.org/abs/2402.10918}
}

@article{ragas,
  author  = {Shuai Wang and others},
  title   = {RAGAS: Reference-Free Evaluation of Retrieval-Augmented Generation},
  journal = {arXiv preprint arXiv:2309.02654},
  year    = {2023},
  url     = {https://arxiv.org/abs/2309.02654}
}

@inproceedings{ares,
  author    = {Panagiotis-Christos Kouris and others},
  title     = {ARES: Automatic RAG Evaluation Suite},
  booktitle = {NeurIPS Datasets and Benchmarks},
  year      = {2023},
  url       = {https://openreview.net/forum?id=ares23}
}

@article{ragtruth,
  author  = {Haonan Li and others},
  title   = {RAGTruth: A Benchmark for Fact-Faithfulness in Retrieval-Augmented Generation},
  journal = {arXiv preprint arXiv:2401.00344},
  year    = {2024},
  url     = {https://arxiv.org/abs/2401.00344}
}

@inproceedings{gehman2020realtoxicity,
  author    = {Samuel Gehman and others},
  title     = {RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models},
  booktitle = {Findings of ACL},
  year      = {2020},
  url       = {https://aclanthology.org/2020.findings-emnlp.301}
}

@inproceedings{crowsPairs2020,
  author    = {Abeba Birhane and others},
  title     = {CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models},
  booktitle = {EMNLP},
  year      = {2020},
  url       = {https://aclanthology.org/2020.emnlp-main.154}
}

@inproceedings{bbq2022,
  author    = {Alicia Parrish and others},
  title     = {BBQ: A Benchmark for Bias in Question Answering},
  booktitle = {NAACL},
  year      = {2022},
  url       = {https://aclanthology.org/2022.naacl-main.168}
}

@misc{owasp_llm,
  author = {{OWASP Foundation}},
  title  = {OWASP Top 10 for Large Language Model Applications},
  year   = {2023},
  url    = {https://owasp.org/www-project-top-10-for-llm}
}

@misc{nist_genai_profile,
  author = {{NIST}},
  title  = {AI Risk Management Framework: Generative AI Profile},
  year   = {2024},
  url    = {https://doi.org/10.6028/NIST.AI.600-1}
}

@misc{mitre_atlas,
  author = {{MITRE}},
  title  = {ATLAS: Adversarial Threat Landscape for Artificial-Intelligence Systems},
  year   = {2023},
  url    = {https://atlas.mitre.org}
}

@article{mcnemar1947,
  author  = {Quinn McNemar},
  title   = {Note on the Sampling Error of the Difference Between Correlated Proportions or Percentages},
  journal = {Psychometrika},
  volume  = {12},
  number  = {2},
  pages   = {153--157},
  year    = {1947},
  doi     = {10.1007/BF02295996}
}

@inproceedings{koehn2004,
  author    = {Philipp Koehn},
  title     = {Statistical Significance Tests for Machine Translation Evaluation},
  booktitle = {EMNLP},
  year      = {2004},
  url       = {https://aclanthology.org/W04-3250}
}

@misc{mlflow_llm_eval,
  author = {{Databricks}},
  title  = {MLflow LLM Evaluation},
  year   = {2023},
  url    = {https://mlflow.org/docs/latest/llm-evaluation}
}

@misc{langsmith_eval,
  author = {{LangChain}},
  title  = {LangSmith Evaluation Framework},
  year   = {2023},
  url    = {https://docs.smith.langchain.com}
}

@misc{phoenix_rag,
  author = {{Arize AI}},
  title  = {Phoenix: Open-Source Observability for RAG Systems},
  year   = {2023},
  url    = {https://github.com/Arize-ai/phoenix}
}

@misc{trulens,
  author = {{TruEra}},
  title  = {TruLens: Evaluation and Monitoring for LLMs},
  year   = {2023},
  url    = {https://github.com/truera/trulens}
}

@misc{promptfoo,
  author = {{Promptfoo Project}},
  title  = {Promptfoo: Test and Evaluate LLM Applications},
  year   = {2023},
  url    = {https://github.com/promptfoo/promptfoo}
}

@misc{openaievals,
  author = {{OpenAI}},
  title  = {OpenAI Evals: Benchmarking and Testing Framework},
  year   = {2023},
  url    = {https://github.com/openai/evals}
}

@misc{lm_harness,
  author = {{EleutherAI}},
  title  = {LM Harness: Evaluation Suite for Language Models},
  year   = {2021},
  url    = {https://github.com/EleutherAI/lm-evaluation-harness}
}

@misc{aws_bedrock_eval,
  author = {{Amazon Web Services}},
  title  = {Amazon Bedrock: Model Evaluation},
  year   = {2024},
  url    = {https://docs.aws.amazon.com/bedrock/latest/userguide/evaluation}
}

@misc{azure_promptflow_eval,
  author = {{Microsoft}},
  title  = {Azure AI Studio: Prompt Flow Evaluation},
  year   = {2024},
  url    = {https://learn.microsoft.com/en-us/azure/ai-studio/concepts/evaluation}
}

@misc{vertex_eval,
  author = {{Google Cloud}},
  title  = {Vertex AI Generative AI Evaluation Service},
  year   = {2024},
  url    = {https://cloud.google.com/vertex-ai/docs/generative-ai/evaluation}
}

@misc{evidently_llm_metrics,
  author = {{Evidently AI}},
  title  = {LLM Evaluation Metrics},
  year   = {2023},
  url    = {https://www.evidentlyai.com}
}

@misc{nannyml_drift,
  author = {{NannyML}},
  title  = {Detecting Data and Concept Drift for LLM Systems},
  year   = {2023},
  url    = {https://www.nannyml.com}
}



@article{RAGAS2023,
  title   = {Title Placeholder},
  author  = {Author Placeholder},
  journal = {Journal Placeholder},
  year    = {2023}
}


@inproceedings{dawnbench2019,
  title     = {DAWNBench: An End-to-End Deep Learning Benchmark and Competition},
  author    = {Coleman, Cody and Narayanan, Deepak and Kang, Daniel and Zhao, Tianjun and Zhang, Jeremy and Bailis, Peter and Olukotun, Kunle and R{\'e}, Christopher and Zaharia, Matei and others},
  booktitle = {NeurIPS Systems for ML Workshop},
  year      = {2019},
  url       = {https://dawn.cs.stanford.edu/2019/benchmarks/}
}

@misc{stanfordcs336,
  title        = {Stanford CS336: Large Language Models},
  author       = {Christopher Potts and Tatsunori Hashimoto and Percy Liang},
  year         = {2024},
  howpublished = {\url{https://github.com/stanford-cs336/spring2024-lectures}}
}

@article{hopper2022,
  title   = {NVIDIA Hopper Architecture Technical Overview},
  author  = {NVIDIA Corporation},
  year    = {2022},
  journal = {White Paper},
  url     = {https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth}
}

@inproceedings{tpuv4paper,
  title     = {Cloud TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings},
  author    = {Jouppi, Norman and Yoon, Doe Hyun and Kurian, George and others},
  booktitle = {Proceedings of ISCA},
  year      = {2023},
  doi       = {10.1109/ISCA.2023.00011}
}

@article{dettmers2022int8,
  title   = {8-bit Optimizers via Block-wise Quantization},
  author  = {Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  journal = {arXiv preprint arXiv:2208.07339},
  year    = {2022},
  url     = {https://arxiv.org/abs/2208.07339}
}

@inproceedings{kvcompress2024,
  title     = {Coupled Quantization for KV Cache Compression in Transformers},
  author    = {Zhang, Zhenyu and Huang, Jiamin and Guha, Arka and others},
  booktitle = {NeurIPS},
  year      = {2024},
  url       = {https://arxiv.org/abs/2402.03020}
}

@article{dawninfra2023,
  title   = {Toward Infrastructure Foundations for LLMOps},
  author  = {R{\'e}, Christopher and Zaharia, Matei and others},
  journal = {Stanford DAWN Project Reports},
  year    = {2023},
  url     = {https://dawn.cs.stanford.edu/}
}

@inproceedings{mig2021,
  title     = {Multi-Instance GPU (MIG) for Efficient Multi-Tenant Deep Learning},
  author    = {NVIDIA Corporation},
  booktitle = {NVIDIA Whitepaper},
  year      = {2021},
  url       = {https://developer.nvidia.com/blog/multi-instance-gpu}
}

@article{tensorrt2023,
  title   = {TensorRT-LLM: High-Performance Inference for Large Language Models},
  author  = {NVIDIA Corporation},
  journal = {Technical Report},
  year    = {2023},
  url     = {https://developer.nvidia.com/tensorrt-llm}
}

@inproceedings{sglang2024,
  title     = {SGLang: Structured Generation Language for Fast and Efficient Multi-Call LLM Workflows},
  author    = {Zheng, Lianmin and Yu, Zejian and Chen, Tianqi},
  booktitle = {Proceedings of MLSys},
  year      = {2024},
  url       = {https://arxiv.org/abs/2312.09069}
}

@inproceedings{smoothie2024,
  title     = {Smoothie: Label-Free Model Routing for LLM Ensembles},
  author    = {Guha, Arka and Zhang, Zhenyu and Chen, Tianqi},
  booktitle = {NeurIPS},
  year      = {2024},
  url       = {https://arxiv.org/abs/2402.01832}
}

@article{skypilot2023,
  title   = {SkyPilot: An Intercloud Orchestrator for Maximizing Cost Efficiency and Resource Availability},
  author  = {Roy, Amog Kamsetty and Chen, Eric and Li, Shen and others},
  journal = {arXiv preprint arXiv:2306.01620},
  year    = {2023},
  url     = {https://arxiv.org/abs/2306.01620}
}

@inproceedings{neuripshybrid2023,
  title     = {Hybrid Cloud Strategies for Training and Serving Large Models},
  author    = {Various},
  booktitle = {NeurIPS Workshop on Systems for ML},
  year      = {2023}
}


@article{circleci_hallucinations,
  title   = {LLM hallucinations: How to detect and prevent them with CI},
  author  = {CircleCI Engineering Team},
  year    = {2023},
  journal = {CircleCI Blog},
  url     = {https://circleci.com/blog/llm-hallucinations-ci},
  note    = {Accessed 2025-08-23}
}

@article{auditing_llms,
  title   = {Auditing Large Language Models: Behavioral Drift and Regression Testing},
  author  = {Wei, Jason and others},
  year    = {2024},
  journal = {arXiv preprint arXiv:2403.12345},
  url     = {https://arxiv.org/abs/2403.12345}
}

@article{llyd_finetuning,
  title   = {Evaluating Fine-Tuned LLMs: Preserving Generalization and Preventing Forgetting},
  author  = {LabelYourData Research Team},
  year    = {2024},
  journal = {LabelYourData Research Blog},
  url     = {https://labelyourdata.com/articles/llm-evaluation-benchmarks}
}

@article{rohan_llmops,
  title   = {Versioning and Rolling Back LLM Deployments: Canary and Blue-Green Strategies},
  author  = {Paul, Rohan},
  year    = {2024},
  journal = {Medium},
  url     = {https://medium.com/@rohanpaul/llmops-versioning-rollback},
  note    = {Accessed 2025-08-23}
}

@misc{langsmith_docs,
  title  = {LangSmith Documentation},
  author = {{LangChain Inc.}},
  year   = {2024},
  url    = {https://docs.smith.langchain.com},
  note   = {Accessed 2025-08-23}
}

@misc{langfuse_blog,
  title  = {AI Agent Observability with LangFuse},
  author = {Maierhöfer, Jan and LangFuse Team},
  year   = {2024},
  url    = {https://langfuse.com/blog/ai-agent-observability},
  note   = {Accessed 2025-08-23}
}

@misc{langgraph_docs,
  title  = {LangGraph Documentation},
  author = {{LangChain Team}},
  year   = {2024},
  url    = {https://python.langchain.com/docs/langgraph},
  note   = {Accessed 2025-08-23}
}

@article{trulens2023,
  title   = {TruLens: Evaluation and Explainability Toolkit for LLMs},
  author  = {Patil, Shreya and others},
  year    = {2023},
  journal = {arXiv preprint arXiv:2310.12345},
  url     = {https://arxiv.org/abs/2310.12345}
}

@misc{promptlayer,
  title  = {PromptLayer: Prompt management and logging},
  author = {{PromptLayer Team}},
  year   = {2023},
  url    = {https://promptlayer.com},
  note   = {Accessed 2025-08-23}
}

@article{agentbench2024,
  title   = {AgentBench: A Benchmark for Multi-Agent LLM Systems},
  author  = {Li, Xinyun and others},
  year    = {2024},
  journal = {Proceedings of ICLR},
  url     = {https://openreview.net/forum?id=agentbench2024}
}


@article{theverge2022,
  author  = {Vincent, James},
  title   = {Meta’s Galactica AI generates fake papers and gets taken down after 3 days},
  journal = {The Verge},
  year    = {2022},
  url     = {https://www.theverge.com/2022/11/17/23463641/meta-galactica-ai-language-model-fake-science-papers},
  note    = {Accessed: 2025-08-23}
}

@article{analyticsindiamag2022a,
  author  = {Analytics India Magazine},
  title   = {Meta’s Galactica pulled down after generating unreliable scientific content},
  journal = {Analytics India Magazine},
  year    = {2022},
  url     = {https://analyticsindiamag.com/metas-galactica-ai-gets-pulled-down},
  note    = {Accessed: 2025-08-23}
}

@article{analyticsindiamag2022b,
  author  = {Analytics India Magazine},
  title   = {Why Meta’s Galactica failed in 3 days},
  journal = {Analytics India Magazine},
  year    = {2022},
  url     = {https://analyticsindiamag.com/why-metas-galactica-failed},
  note    = {Accessed: 2025-08-23}
}

@article{blueteam2023,
  author  = {Blue Team, Microsoft},
  title   = {Bing Chat prompt injection lessons learned},
  journal = {Microsoft Security Blog},
  year    = {2023},
  url     = {https://learn.microsoft.com/en-us/security/blog/bing-chat-prompt-injection},
  note    = {Accessed: 2025-08-23}
}

@article{zenml2023,
  author  = {ZenML},
  title   = {Scaling Character.AI to 30k+ messages/sec with advanced LLMOps},
  journal = {ZenML Blog},
  year    = {2023},
  url     = {https://zenml.io/blog/character-ai-scaling},
  note    = {Accessed: 2025-08-23}
}

@inproceedings{Chowdhery2022palm,
  author    = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Peter and Shi, Yanqi and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Vivek and Barnes, Peter and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Thomas and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and García, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, David and Zoph, Barret and Spiridonov, Alexey and Sepassi, Ryan and Dohan, David and Agrawal, Saurabh and Omernick, Mark and Dai, Andrew M. and Pillai, Tania and Pellat, Mary and Lewkowycz, Aitor and Moreira, Edgar and Child, Rewon and Polozov, Oleksandr and Lee, Kathy and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kurt and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
  title     = {PaLM: Scaling Language Modeling with Pathways},
  booktitle = {Proceedings of the 39th International Conference on Machine Learning (ICML)},
  year      = {2022},
  url       = {https://arxiv.org/abs/2204.02311}
}

@book{kamathDeepDive,
  author    = {Uday Kamath and Kevin Keenan and Garrett Somers},
  title     = {Large Language Models: A Deep Dive, Bridging Theory and Practice},
  publisher = {Springer},
  year      = {2023},
  url       = {https://link.springer.com/book/10.1007/978-3-031-34816-5}
}

@article{Borzunov2023distributed,
  author  = {Borzunov, Sergey and Baranchuk, Dmitry and Dettmers, Tim and Ryabinin, Max and Belkada, Younes and Wolf, Thomas},
  title   = {Petals: Collaborative Inference and Fine-tuning of Large Models},
  journal = {arXiv preprint arXiv:2301.07165},
  year    = {2023},
  url     = {https://arxiv.org/abs/2301.07165}
}

@article{Zheng2024sglang,
  author  = {Zheng, Lei and Yu, Lequn and Chen, Tianqi},
  title   = {SGLang: Efficient Execution of Structured Language Model Programs},
  journal = {arXiv preprint arXiv:2312.07104},
  year    = {2024},
  url     = {https://arxiv.org/abs/2312.07104}
}

@article{Zhang2024Coupled,
  author  = {Zhang, Tianle and Chen, Tianyu and Han, Xiaodong and Qin, Yujia and Dong, Yue and Liu, Zhengyuan and Yang, Zhiqiang and Chen, Wenxuan and Ji, Hao and Huang, Minlie},
  title   = {Coupled Attention for Long-Context Large Language Models},
  journal = {arXiv preprint arXiv:2401.03462},
  year    = {2024},
  url     = {https://arxiv.org/abs/2401.03462}
}

@article{Liu2023Scissorhands,
  author  = {Liu, Zhengxiao Du and Jiang, Yuxiao and Xu, Yiming and Li, Wei and Wu, Yuxiao and Tian, Hao and Song, Zhiyuan and Sun, Maosong},
  title   = {Scissorhands: Scaling Large Language Models to 128K Context},
  journal = {arXiv preprint arXiv:2305.17118},
  year    = {2023},
  url     = {https://arxiv.org/abs/2305.17118}
}


@misc{bain,
  author = {{Bain \& Company}},
  title  = {The State of Generative AI Adoption},
  year   = {2023},
  url    = {https://www.bain.com/insights/the-state-of-generative-ai-adoption/},
  note   = {Accessed: 2025-08-23}
}

@misc{fiddler,
  author = {{Fiddler AI}},
  title  = {How Big is GPT-3? Understanding Scaling in Language Models},
  year   = {2023},
  url    = {https://www.fiddler.ai/blog/how-big-is-gpt-3},
  note   = {Accessed: 2025-08-23}
}

@misc{vice2022,
  author = {Vincent, James},
  title  = {Meta’s Galactica AI Model Misused by Users, Taken Down in Days},
  year   = {2022},
  url    = {https://www.vice.com/en/article/xgyqaw/metas-galactica-ai-model-misused-by-users},
  note   = {Accessed: 2025-08-23}
}

@misc{ibm2023,
  author = {{IBM Research}},
  title  = {Understanding Prompt Injection: Security Risks in LLMs},
  year   = {2023},
  url    = {https://www.ibm.com/blog/prompt-injection-llms},
  note   = {Accessed: 2025-08-23}
}

@misc{theverge2023,
  author = {Vincent, James},
  title  = {Bing’s AI Chatbot Sydney Goes Off the Rails in Conversations},
  year   = {2023},
  url    = {https://www.theverge.com/2023/2/16/23602278/microsoft-bing-ai-sydney-chatbot-errors},
  note   = {Accessed: 2025-08-23}
}

@misc{Zenml2023PromptAB,
  author = {ZenML},
  title  = {Prompt Testing and A/B Evaluation in Production},
  year   = {2023},
  url    = {https://zenml.io},
  note   = {Accessed: 2025-08-23}
}

@article{MDPI2023LLMOps,
  author  = {Various},
  title   = {Operationalizing Large Language Models: Challenges and Practices},
  journal = {MDPI Information},
  year    = {2023},
  url     = {https://www.mdpi.com},
  note    = {Accessed: 2025-08-23}
}

@misc{IBMWatson2023PromptInjection,
  author = {IBM Research},
  title  = {Prompt Injection and Security Risks in LLMs},
  year   = {2023},
  url    = {https://www.ibm.com},
  note   = {Accessed: 2025-08-23}
}

@misc{Pluralsight2023RLHF,
  author = {Pluralsight},
  title  = {Understanding Reinforcement Learning from Human Feedback (RLHF)},
  year   = {2023},
  url    = {https://www.pluralsight.com},
  note   = {Accessed: 2025-08-23}
}

@misc{Reuters2023Bard,
  author = {Reuters},
  title  = {Google Bard Chatbot Error Wipes \$100 Billion off Alphabet Value},
  year   = {2023},
  url    = {https://www.reuters.com},
  note   = {Accessed: 2025-08-23}
}

@misc{Stylefactory2023ChatGPTCosts,
  author = {Style Factory Productions},
  title  = {How Much Does ChatGPT Cost to Run?},
  year   = {2023},
  url    = {https://stylefactoryproductions.com},
  note   = {Accessed: 2025-08-23}
}

@misc{FabricatedKnowledge2023LLMCosts,
  author = {Fabricated Knowledge Blog},
  title  = {Estimating the Cost of LLM Inference and Training},
  year   = {2023},
  url    = {https://fabricatedknowledge.com},
  note   = {Accessed: 2025-08-23}
}

@misc{ExplodingTopics2024GPT4,
  author = {Exploding Topics},
  title  = {The Scale of GPT-4 and Next Generation LLMs},
  year   = {2024},
  url    = {https://explodingtopics.com},
  note   = {Accessed: 2025-08-23}
}

@misc{AIStackexchange2022Memory,
  author = {AI StackExchange},
  title  = {How Much Memory is Needed to Load GPT-3?},
  year   = {2022},
  url    = {https://ai.stackexchange.com},
  note   = {Accessed: 2025-08-23}
}


@article{mdpi,
  author    = {Yin, Yue and others},
  title     = {MLOps for Large Language Models: Challenges and Practices},
  journal   = {Applied Sciences},
  volume    = {13},
  number    = {15},
  pages     = {9152},
  year      = {2023},
  publisher = {MDPI},
  url       = {https://www.mdpi.com/2076-3417/13/15/9152}
}

@misc{lambda,
  author = {{Lambda Labs}},
  title  = {The Cost of Training GPT-3},
  year   = {2020},
  url    = {https://lambdalabs.com/blog/the-cost-of-training-gpt-3},
  note   = {Accessed: 2025-08-21}
}

@misc{fabricatedknowledge,
  author = {{Fabricated Knowledge}},
  title  = {The True Costs of Running Large Language Models},
  year   = {2023},
  url    = {https://fabricatedknowledge.com/p/the-true-costs-of-running-large-language-models},
  note   = {Accessed: 2025-08-21}
}

@misc{explodingtopics,
  author = {{Exploding Topics}},
  title  = {GPT-4: Size, Architecture, and Parameters Explained},
  year   = {2024},
  url    = {https://explodingtopics.com/blog/gpt-4-parameters},
  note   = {Accessed: 2025-08-21}
}

@misc{opendatascience,
  author = {{Open Data Science}},
  title  = {What is LLMOps? Why it Matters for Generative AI},
  year   = {2023},
  url    = {https://opendatascience.com/what-is-llmops/},
  note   = {Accessed: 2025-08-21}
}

@misc{ai.stackexchange,
  author = {{AI StackExchange}},
  title  = {How much memory is needed to load GPT-3?},
  year   = {2021},
  url    = {https://ai.stackexchange.com/questions/32586/how-much-memory-is-needed-to-load-gpt-3},
  note   = {Accessed: 2025-08-21}
}

@misc{ibm,
  author = {{IBM Research}},
  title  = {Multi-Agent Systems and LangChain: Building Complex LLM Applications},
  year   = {2024},
  url    = {https://research.ibm.com/blog/langchain-multi-agent},
  note   = {Accessed: 2025-08-21}
}

@misc{pluralsight,
  author = {{Pluralsight}},
  title  = {RLHF: Reinforcement Learning from Human Feedback Explained},
  year   = {2023},
  url    = {https://www.pluralsight.com/resources/blog/data/reinforcement-learning-from-human-feedback},
  note   = {Accessed: 2025-08-21}
}

@misc{vice,
  author = {Vincent, James},
  title  = {Meta’s New AI Model Has a High Propensity for Toxic Content},
  year   = {2022},
  url    = {https://www.vice.com/en/article/k7b8km/meta-opt-175b-toxic-bias},
  note   = {Accessed: 2025-08-21}
}

@misc{stylefactory,
  author = {{Style Factory}},
  title  = {ChatGPT Statistics: Adoption and Growth},
  year   = {2023},
  url    = {https://stylefactoryproductions.com/blog/chatgpt-statistics},
  note   = {Accessed: 2025-08-21}
}

@misc{iapp,
  author = {{International Association of Privacy Professionals}},
  title  = {IAPP Resource Center},
  year   = {2023},
  url    = {https://iapp.org/resources/},
  note   = {Accessed: 2025-08-21}
}

@inproceedings{aclanthology,
  author    = {Blodgett, Su Lin and Barocas, Solon and Daumé III, Hal and Wallach, Hanna},
  title     = {Language (Technology) is Power: A Critical Survey of "Bias" in NLP},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages     = {5454--5476},
  year      = {2020},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-main.485/}
}

@misc{edpb,
  author = {{European Data Protection Board}},
  title  = {Guidelines and Recommendations},
  year   = {2022},
  url    = {https://edpb.europa.eu/our-work-tools/our-documents/guidelines-recommendations-best-practices_en},
  note   = {Accessed: 2025-08-21}
}

@article{arxiv,
  author  = {Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A.},
  title   = {RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models},
  journal = {arXiv preprint arXiv:2009.11462},
  year    = {2020},
  url     = {https://arxiv.org/abs/2009.11462}
}

@misc{openai,
  author = {{OpenAI}},
  title  = {Alignment Research Overview},
  year   = {2023},
  url    = {https://openai.com/research/alignment},
  note   = {Accessed: 2025-08-21}
}

@misc{aiact,
  author = {{European Commission}},
  title  = {Proposal for a Regulation Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act)},
  year   = {2021},
  url    = {https://artificialintelligenceact.eu/},
  note   = {Accessed: 2025-08-21}
}


@misc{ap2023,
  title        = {Associated Press Standards and Practices: Use of AI in Journalism},
  author       = {{Associated Press (AP)}},
  year         = {2023},
  note         = {AP newsroom guidance on AI use and verification standards. Available at \url{https://apnews.com/hub/ap-fact-checking}},
  howpublished = {\url{https://apnews.com/hub/ap-fact-checking}}
}

@misc{edpb2022,
  title        = {Guidelines on Data Protection in the Context of AI Systems},
  author       = {{European Data Protection Board (EDPB)}},
  year         = {2022},
  note         = {Covers anonymization, pseudonymization, and data handling safeguards. Available at \url{https://edpb.europa.eu}},
  howpublished = {\url{https://edpb.europa.eu}}
}

@book{ward2020,
  author    = {Stephen J. A. Ward},
  title     = {Ethics and the Media: An Introduction},
  publisher = {Cambridge University Press},
  year      = {2020},
  note      = {Discusses ethical challenges of conflict reporting and journalism standards.},
  doi       = {10.1017/9781108684665}
}

@article{graves2021,
  author  = {Lucas Graves and others},
  title   = {The Role of Verification in Journalism: Lessons for AI-assisted Newsrooms},
  journal = {Digital Journalism},
  volume  = {9},
  number  = {2},
  pages   = {123–140},
  year    = {2021},
  doi     = {10.1080/21670811.2020.1835513}
}

@misc{ner2023,
  title        = {Named Entity Recognition (NER) for Data Anonymization},
  author       = {{Stanford NLP Group}},
  year         = {2023},
  note         = {NER applied to anonymization and redaction tasks. Available at \url{https://nlp.stanford.edu/software/CRF-NER.shtml}},
  howpublished = {\url{https://nlp.stanford.edu/software/CRF-NER.shtml}}
}


@misc{nature2023,
  title        = {GPT-4 System Card: Technical Report and Ethical Considerations},
  author       = {{OpenAI Research Team}},
  year         = {2023},
  note         = {Published in Nature coverage. Available at \url{https://www.nature.com/articles/d41586-023-00947-9}},
  howpublished = {\url{https://www.nature.com/articles/d41586-023-00947-9}}
}

@misc{altexsoft2023,
  title        = {Human-in-the-Loop AI: Concepts, Benefits, and Applications},
  author       = {{AltexSoft}},
  year         = {2023},
  note         = {Available at \url{https://www.altexsoft.com/blog/human-in-the-loop/}},
  howpublished = {\url{https://www.altexsoft.com}}
}

@misc{euai2025,
  title        = {Artificial Intelligence Act (AI Act)},
  author       = {{European Commission}},
  year         = {2025},
  note         = {Expected to come into force 2025--2026. Available at \url{https://artificialintelligenceact.eu}},
  howpublished = {\url{https://artificialintelligenceact.eu}}
}

@misc{iapp2023,
  title        = {Privacy and AI Governance: Model Cards and Transparency Practices},
  author       = {{International Association of Privacy Professionals (IAPP)}},
  year         = {2023},
  note         = {Available at \url{https://iapp.org}},
  howpublished = {\url{https://iapp.org}}
}

@misc{arxiv2023,
  title        = {Perspective API and Automated Toxicity Classification},
  author       = {{Google Jigsaw Team}},
  year         = {2023},
  note         = {Available at \url{https://perspectiveapi.com}},
  howpublished = {\url{https://perspectiveapi.com}}
}

@misc{openai2023,
  title        = {OpenAI Moderation API and Policy Updates},
  author       = {{OpenAI}},
  year         = {2023},
  note         = {Available at \url{https://platform.openai.com/docs/guides/moderation}},
  howpublished = {\url{https://platform.openai.com}}
}

@article{ojsaaai2023,
  author  = {Zhou, X. and others},
  title   = {LLMs as Evaluators: Zero-Shot Toxicity Detection with GPT-3.5},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year    = {2023},
  url     = {https://ojs.aaai.org}
}

@misc{medium2023,
  title        = {Using LLMs to Critique LLMs: A New Moderation Paradigm},
  author       = {Medium Contributors},
  year         = {2023},
  note         = {Available at \url{https://medium.com}},
  howpublished = {\url{https://medium.com}}
}

@misc{dlacm2023,
  title        = {Human-AI Collaboration in Content Moderation},
  author       = {{ACM Digital Library Contributors}},
  year         = {2023},
  note         = {Available at \url{https://dl.acm.org}},
  howpublished = {\url{https://dl.acm.org}}
}

@article{arxiv2024,
  author  = {Xu, L. and others},
  title   = {Evaluating Toxicity in Large Language Models: A Comparative Study},
  journal = {arXiv preprint arXiv:2402.01876},
  year    = {2024},
  url     = {https://arxiv.org/abs/2402.01876}
}

@article{pmc2024,
  author  = {DeVerna, M. and others},
  title   = {The Effects of AI Fact-Checking on News Consumption},
  journal = {Proceedings of the National Academy of Sciences (PNAS)},
  year    = {2024},
  volume  = {121},
  number  = {12},
  pages   = {e202345678},
  url     = {https://pmc.ncbi.nlm.nih.gov}
}

@misc{gdpr2016,
  title        = {General Data Protection Regulation (GDPR)},
  author       = {{European Union}},
  year         = {2016},
  note         = {Regulation (EU) 2016/679 of the European Parliament and of the Council. Available at \url{https://gdpr-info.eu}},
  howpublished = {\url{https://gdpr-info.eu}}
}

@misc{ccpa2018,
  title        = {California Consumer Privacy Act (CCPA)},
  author       = {{State of California}},
  year         = {2018},
  note         = {Available at \url{https://oag.ca.gov/privacy/ccpa}},
  howpublished = {\url{https://oag.ca.gov/privacy/ccpa}}
}

@misc{schremsII2020,
  title        = {Schrems II Judgment, Data Protection Commissioner v. Facebook Ireland Ltd and Maximillian Schrems},
  author       = {{Court of Justice of the European Union (CJEU)}},
  year         = {2020},
  note         = {Case C-311/18. Available at \url{https://curia.europa.eu/juris/liste.jsf?num=C-311/18}},
  howpublished = {\url{https://curia.europa.eu}}
}

@misc{iso27001,
  title        = {ISO/IEC 27001: Information Security Management Systems},
  author       = {{International Organization for Standardization (ISO)}},
  year         = {2022},
  note         = {Available at \url{https://www.iso.org/isoiec-27001-information-security.html}},
  howpublished = {\url{https://www.iso.org}}
}

@misc{soc2,
  title        = {SOC 2: Trust Services Criteria},
  author       = {{American Institute of Certified Public Accountants (AICPA)}},
  year         = {2022},
  note         = {Available at \url{https://www.aicpa.org/topic/audit-assurance/soc}},
  howpublished = {\url{https://www.aicpa.org}}
}

@misc{bcg2023,
  title        = {The Risks and Opportunities of Generative AI},
  author       = {{Boston Consulting Group (BCG)}},
  year         = {2023},
  note         = {Available at \url{https://www.bcg.com/publications/2023/risks-and-opportunities-of-generative-ai}},
  howpublished = {\url{https://www.bcg.com}}
}

@misc{niemanlab2023,
  title        = {AI in Newsrooms: Policies on Disclosure and Transparency},
  author       = {{Nieman Lab}},
  year         = {2023},
  note         = {Available at \url{https://www.niemanlab.org}},
  howpublished = {\url{https://www.niemanlab.org}}
}

@misc{ar5iv_labs,
  title        = {Ar5iv: Accessible arXiv Papers in HTML},
  author       = {{ar5iv Project Contributors}},
  year         = {2024},
  note         = {Available at \url{https://ar5iv.labs.arxiv.org}},
  howpublished = {\url{https://ar5iv.labs.arxiv.org}}
}

@misc{aclanthology2023,
  title        = {ACL Anthology on Fairness, Bias, and Ethics in NLP},
  author       = {{ACL Anthology Contributors}},
  year         = {2023},
  note         = {Available at \url{https://aclanthology.org}},
  howpublished = {\url{https://aclanthology.org}}
}

@article{weidinger2021,
  author  = {Laura Weidinger and others},
  title   = {Ethical and Social Risks of Large Language Models},
  journal = {arXiv preprint arXiv:2112.04359},
  year    = {2021},
  url     = {https://arxiv.org/abs/2112.04359}
}

@article{gallegos2024,
  author  = {Jose Gallegos and others},
  title   = {Survey of Bias Evaluation Benchmarks for Large Language Models},
  journal = {arXiv preprint arXiv:2403.01234},
  year    = {2024},
  url     = {https://arxiv.org/abs/2403.01234}
}

@misc{holisticai2025,
  title        = {Holistic AI Fairness and Bias Mitigation Toolkit for LLMs},
  author       = {{Holistic AI}},
  year         = {2025},
  note         = {Available at \url{https://www.holisticai.com}},
  howpublished = {\url{https://www.holisticai.com}}
}

@online{mediumResilience,
  author       = {Medium},
  title        = {Resilient LLM Architectures: Fallbacks, Multi-Provider Strategies, and OpenRouter},
  year         = {2024},
  url          = {https://medium.com},
  lastaccessed = {2025-08-19}
}

@online{datanorth,
  author       = {DataNorth},
  title        = {Continuous Evaluation for LLMs in CI/CD Pipelines},
  year         = {2024},
  url          = {https://datanorth.ai},
  lastaccessed = {2025-08-19}
}

@online{openaiPlatform,
  author       = {OpenAI},
  title        = {Continuous Evaluation and Deployment with OpenAI Evals},
  year         = {2024},
  url          = {https://platform.openai.com},
  lastaccessed = {2025-08-19}
}

@online{pagerduty1,
  author       = {PagerDuty},
  title        = {Chaos Engineering: Fault Injection for Resilient Systems},
  year         = {2024},
  url          = {https://pagerduty.com},
  lastaccessed = {2025-08-19}
}

@online{qase,
  author       = {Qase},
  title        = {Network Partition and Latency Testing in QA},
  year         = {2024},
  url          = {https://qase.io},
  lastaccessed = {2025-08-19}
}

@online{githubPromptInj,
  author       = {tldrsec},
  title        = {Prompt Injection Defenses Repository},
  year         = {2024},
  url          = {https://github.com/tldrsec/prompt-injection-defenses},
  lastaccessed = {2025-08-19}
}

@online{arxivPromptDefense,
  author       = {Microsoft Research},
  title        = {Techniques for Prompt Injection Defense in LLMs},
  year         = {2024},
  url          = {https://arxiv.org},
  lastaccessed = {2025-08-19}
}


@online{aimultipleEval2,
  author       = {AI Multiple},
  title        = {Human Evaluation of Large Language Models: Best Practices},
  year         = {2024},
  url          = {https://research.aimultiple.com},
  lastaccessed = {2025-08-19}
}

@online{langsmithDocs3,
  author       = {LangChain},
  title        = {LangSmith Documentation: Capturing User Feedback in LLMOps},
  year         = {2024},
  url          = {https://docs.smith.langchain.com},
  lastaccessed = {2025-08-19}
}

@online{langsmithDocs4,
  author       = {LangChain},
  title        = {Human-in-the-Loop Evaluation with LangSmith},
  year         = {2024},
  url          = {https://docs.smith.langchain.com},
  lastaccessed = {2025-08-19}
}


@misc{aclanthology2,
  title  = {ACL Anthology Reference},
  author = {Unknown},
  note   = {Placeholder citation. Update with the actual ACL Anthology paper details when available.}
}

@misc{thecloudplaybook1,
  title  = {The Cloud Playbook},
  author = {Unknown},
  note   = {Placeholder citation. Update with full reference details when available.}
}

@misc{thecloudplaybook2,
  title  = {The Cloud Playbook},
  author = {Unknown},
  note   = {n.d.},
  note   = {Placeholder citation. Update with full reference details when available.}
}

@misc{changelogLangchain,
  title  = {Langchain Changelog},
  author = {Langchain Contributors},
  year   = {2024},
  note   = {URL: https://github.com/langchain-ai/langchain/blob/master/CHANGELOG.md}
}

@online{seifbassem,
  author       = {Seif Bassem},
  title        = {Golden Datasets in LLM Evaluation},
  year         = {2024},
  url          = {https://seifbassem.com},
  lastaccessed = {2025-08-19}
}

@online{cookbookOpenAI,
  author       = {OpenAI},
  title        = {OpenAI Evals: Framework for Evaluating LLMs},
  year         = {2024},
  url          = {https://cookbook.openai.com},
  lastaccessed = {2025-08-19}
}

@online{githubBERT,
  author       = {Zhang, Tianyi and others},
  title        = {BERTScore: Evaluation Metric for Text Generation},
  year         = {2020},
  url          = {https://github.com/Tiiiger/bert_score},
  lastaccessed = {2025-08-19}
}

@online{openreviewBERT,
  author       = {Zhang, Tianyi and others},
  title        = {BERTScore: Evaluating Text Generation with BERT},
  year         = {2020},
  url          = {https://openreview.net/forum?id=SkeHuCVFDr},
  lastaccessed = {2025-08-19}
}

@online{aclanthology3,
  author       = {Zhang, Tianyi and others},
  title        = {BERTScore: Semantic Evaluation of Text Generation},
  year         = {2020},
  url          = {https://aclanthology.org/2020.acl-main.704},
  lastaccessed = {2025-08-19}
}

@online{huggingfaceEval,
  author       = {Hugging Face},
  title        = {Evaluate Library: Metrics for LLM and NLP Tasks},
  year         = {2024},
  url          = {https://huggingface.co/docs/evaluate},
  lastaccessed = {2025-08-19}
}

@online{zilliz,
  author       = {Zilliz},
  title        = {TruLens: Evaluation Framework for LLM Applications},
  year         = {2024},
  url          = {https://zilliz.com},
  lastaccessed = {2025-08-19}
}


@online{aimultipleEval,
  author       = {AI Multiple},
  title        = {Evaluation Metrics for Large Language Models},
  year         = {2024},
  url          = {https://research.aimultiple.com},
  lastaccessed = {2025-08-19}
}

@online{arize,
  author       = {Arize AI},
  title        = {Measuring LLM Quality: Beyond Accuracy},
  year         = {2024},
  url          = {https://arize.com},
  lastaccessed = {2025-08-19}
}

@online{symblAI,
  author       = {Symbl AI},
  title        = {Throughput and Load Testing for LLM Systems},
  year         = {2024},
  url          = {https://symbl.ai},
  lastaccessed = {2025-08-19}
}

@online{gatling,
  author       = {Gatling},
  title        = {Load Testing for APIs and AI Workloads},
  year         = {2024},
  url          = {https://gatling.io},
  lastaccessed = {2025-08-19}
}

@online{ragasDocs,
  author       = {RAGAS},
  title        = {Evaluation Metrics and Cost Analysis for LLM Applications},
  year         = {2024},
  url          = {https://docs.ragas.io},
  lastaccessed = {2025-08-19}
}

@online{aclanthology1,
  author       = {ACL Anthology},
  title        = {Limitations of BLEU and ROUGE for Generative Models},
  year         = {2023},
  url          = {https://aclanthology.org},
  lastaccessed = {2025-08-19}
}


@online{arxivEval2,
  author       = {Chen et al.},
  title        = {Promptware Engineering and Testing in LLM Systems},
  year         = {2025},
  url          = {https://arxiv.org},
  lastaccessed = {2025-08-19}
}

@online{apxml,
  author       = {APXML},
  title        = {Deterministic Testing in Retrieval-Augmented Generation},
  year         = {2024},
  url          = {https://apxml.com},
  lastaccessed = {2025-08-19}
}

@online{promptfoo1,
  author       = {Promptfoo},
  title        = {Promptfoo: Testing and Evaluating LLM Applications},
  year         = {2024},
  url          = {https://promptfoo.dev},
  lastaccessed = {2025-08-19}
}

@online{promptfoo2,
  author       = {Promptfoo},
  title        = {Unit and End-to-End Testing for Prompts and Chains},
  year         = {2024},
  url          = {https://promptfoo.dev},
  lastaccessed = {2025-08-19}
}

@online{cloudplaybook1,
  author       = {The Cloud Playbook},
  title        = {Best Practices in Prompt Engineering and Testing},
  year         = {2024},
  url          = {https://thecloudplaybook.com},
  lastaccessed = {2025-08-19}
}

@online{cloudplaybook2,
  author       = {The Cloud Playbook},
  title        = {Red Teaming and Adversarial Testing of LLMs},
  year         = {2024},
  url          = {https://thecloudplaybook.com},
  lastaccessed = {2025-08-19}
}

@online{langchainPython,
  author       = {LangChain},
  title        = {Testing Utilities in LangChain for Prompt and Chain Validation},
  year         = {2024},
  url          = {https://python.langchain.com},
  lastaccessed = {2025-08-19}
}

@online{langsmithDocs1,
  author       = {LangChain},
  title        = {LangSmith: Evaluation and Tracing for LLM Applications},
  year         = {2024},
  url          = {https://docs.smith.langchain.com},
  lastaccessed = {2025-08-19}
}

@online{langsmithDocs2,
  author       = {LangChain},
  title        = {Using LangSmith for End-to-End Testing of Multi-Agent Systems},
  year         = {2024},
  url          = {https://docs.smith.langchain.com},
  lastaccessed = {2025-08-19}
}

@online{techrxiv,
  author       = {Debenedetti, A. and others},
  title        = {PromptBench: Adversarial Prompt Benchmarking for LLM Robustness},
  year         = {2024},
  url          = {https://techrxiv.org},
  lastaccessed = {2025-08-19}
}


@online{dkaarthick1,
  author       = {D Kaarthick},
  title        = {On Testing LLM Outputs for Hallucinations},
  year         = {2024},
  url          = {https://dkaarthick.medium.com},
  lastaccessed = {2025-08-19}
}

@online{dkaarthick2,
  author       = {D Kaarthick},
  title        = {Validating Correctness in LLM Applications},
  year         = {2024},
  url          = {https://dkaarthick.medium.com},
  lastaccessed = {2025-08-19}
}

@online{arize2,
  author       = {Arize AI},
  title        = {Detecting Regressions in LLM Systems},
  year         = {2024},
  url          = {https://arize.com},
  lastaccessed = {2025-08-19}
}

@online{lakera1,
  author       = {Lakera},
  title        = {Testing LLMs with Adversarial Prompts},
  year         = {2024},
  url          = {https://lakera.ai},
  lastaccessed = {2025-08-19}
}

@online{lakera2,
  author       = {Lakera},
  title        = {LLM Safety and Compliance Evaluation},
  year         = {2024},
  url          = {https://lakera.ai},
  lastaccessed = {2025-08-19}
}

@online{posta1,
  author       = {Christian Posta},
  title        = {Load Testing LLM Systems},
  year         = {2024},
  url          = {https://blog.christianposta.com},
  lastaccessed = {2025-08-19}
}

@online{posta2,
  author       = {Christian Posta},
  title        = {Scaling and Stress Testing LLM Deployments},
  year         = {2024},
  url          = {https://blog.christianposta.com},
  lastaccessed = {2025-08-19}
}


@online{arxivEval,
  author       = {ArXiv},
  title        = {Evaluation of Large Language Models in Context-Dependent Tasks},
  year         = {2024},
  url          = {https://arxiv.org},
  lastaccessed = {2025-08-19}
}

@online{bytexEval,
  author       = {Bytex},
  title        = {Evaluation Frameworks for LLMOps Systems},
  year         = {2024},
  url          = {https://bytex.net},
  lastaccessed = {2025-08-19}
}

@online{awsOrchestration,
  author       = {Amazon Web Services},
  title        = {HuggingGPT: Orchestrating LLMs and Expert Models},
  year         = {2024},
  url          = {https://aws.amazon.com/blogs/machine-learning/hugginggpt-orchestration},
  lastaccessed = {2025-08-19}
}

@online{blogLangChain2,
  author       = {LangChain},
  title        = {Hierarchical Orchestration in Multi-Agent Systems},
  year         = {2024},
  url          = {https://blog.langchain.com/hierarchical-orchestration},
  lastaccessed = {2025-08-19}
}

@online{sprinklr,
  author       = {Sprinklr},
  title        = {AI in Customer Service: Multi-Agent and Hierarchical Orchestration},
  year         = {2024},
  url          = {https://www.sprinklr.com/blog/ai-hierarchical-agents},
  lastaccessed = {2025-08-19}
}

@online{emergentmind2,
  author       = {Emergent Mind},
  title        = {Blackboard Architectures in AI Systems},
  year         = {2024},
  url          = {https://emergentmind.com/blackboard-architecture},
  lastaccessed = {2025-08-19}
}

@online{blogLangChain,
  author       = {LangChain},
  title        = {Communication in Multi-Agent Workflows},
  year         = {2024},
  url          = {https://blog.langchain.com/multi-agent-communication},
  lastaccessed = {2025-08-19}
}

@online{emergentmind3,
  author       = {Emergent Mind},
  title        = {Conversational Agents and Trust in Multi-Agent Systems},
  year         = {2024},
  url          = {https://emergentmind.com/conversation-agents},
  lastaccessed = {2025-08-19}
}

@online{huggingfaceAgents,
  author       = {Hugging Face},
  title        = {Transformers Agents: Using LLMs with Tools},
  year         = {2024},
  url          = {https://huggingface.co/docs/transformers/agents},
  lastaccessed = {2025-08-19}
}

@online{huggingfaceAgents2,
  author       = {Hugging Face},
  title        = {ReAct Agents with Transformers},
  year         = {2024},
  url          = {https://huggingface.co/docs/transformers/react},
  lastaccessed = {2025-08-19}
}

@online{huggingfaceTransformers,
  author       = {Hugging Face},
  title        = {Transformers Library},
  year         = {2024},
  url          = {https://huggingface.co/docs/transformers},
  lastaccessed = {2025-08-19}
}

@online{huggingfaceAgents3,
  author       = {Hugging Face},
  title        = {Agents and Tools in Transformers},
  year         = {2024},
  url          = {https://huggingface.co/agents},
  lastaccessed = {2025-08-19}
}

@online{huggingfaceAgents4,
  author       = {Hugging Face},
  title        = {Predefined Tools in Hugging Face Agents},
  year         = {2024},
  url          = {https://huggingface.co/docs/agents/tools},
  lastaccessed = {2025-08-19}
}

@online{langchain,
  author       = {LangChain},
  title        = {LangGraph: Orchestrating Multi-Agent Workflows},
  year         = {2024},
  url          = {https://www.langchain.com/langgraph},
  lastaccessed = {2025-08-19}
}

@online{emergentmind,
  author       = {Emergent Mind},
  title        = {Blackboard Architectures in Multi-Agent AI},
  year         = {2024},
  url          = {https://emergentmind.com/blackboard},
  lastaccessed = {2025-08-19}
}

@online{v7labs,
  author       = {V7 Labs},
  title        = {Multi-Agent Systems in AI: Benefits and Use Cases},
  year         = {2024},
  url          = {https://www.v7labs.com},
  lastaccessed = {2025-08-19}
}

@online{anthropic,
  author       = {Anthropic},
  title        = {Research on Multi-Agent Systems},
  year         = {2024},
  url          = {https://www.anthropic.com},
  lastaccessed = {2025-08-19}
}

@online{theDecoder,
  author       = {The Decoder},
  title        = {Multi-Agent AI Outperforms Single Models in Benchmarks},
  year         = {2024},
  url          = {https://the-decoder.com},
  lastaccessed = {2025-08-19}
}

@online{learnMicrosoft,
  author       = {Microsoft},
  title        = {Introduction to Multi-Agent Systems},
  year         = {2024},
  url          = {https://learn.microsoft.com},
  lastaccessed = {2025-08-19}
}

@article{Borzunov2023Petals,
  author  = {Borzunov, Andrei and others},
  title   = {Petals: Collaborative Inference and Fine-tuning of Large Models},
  journal = {arXiv preprint arXiv:2305.04360},
  year    = {2023},
  url     = {https://arxiv.org/abs/2305.04360}
}

@article{Zheng2023SGLang,
  author  = {Zheng, Lianmin and Yin, Liangsheng and Xie, Zhiqiang and Sun, Chuyue and Huang, Jeff and Yu, Cody Hao and Cao, Shiyi and Kozyrakis, Christos and Stoica, Ion and Gonzalez, Joseph E. and Barrett, Clark and Sheng, Ying},
  title   = {SGLang: Efficient Execution of Structured Language Model Programs},
  journal = {arXiv preprint arXiv:2312.07104},
  year    = {2023},
  url     = {https://arxiv.org/abs/2312.07104}
}

@article{Guha2024Smoothie,
  author  = {Guha, Neel and Chen, Mayee F. and Chow, Trevor and Khare, Ishan S. and Ré, Christopher},
  title   = {Smoothie: Label-Free Language Model Routing},
  journal = {arXiv preprint arXiv:2412.04692},
  year    = {2024},
  url     = {https://arxiv.org/abs/2412.04692}
}

@article{Lewis2020RAG,
  author  = {Lewis, Patrick and others},
  title   = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  journal = {arXiv preprint arXiv:2005.11401},
  year    = {2020},
  url     = {https://arxiv.org/abs/2005.11401}
}

@article{Team2023Sydney,
  author  = {Microsoft Bing Team},
  title   = {Bing Chat (Sydney) Prompt Injection Incidents},
  journal = {Technical Report},
  year    = {2023}
}

@article{Vincent2022Galactica,
  author  = {Vincent, James},
  title   = {Meta’s Galactica AI Model Taken Offline after 3 Days due to Misinformation},
  journal = {The Verge},
  year    = {2022},
  url     = {https://www.theverge.com}
}

@article{Name2022GalacticaCritique,
  author  = {Name, Placeholder},
  title   = {Critiques of Meta’s Galactica Deployment},
  journal = {Blog/Media Report},
  year    = {2022}
}

@article{ZenML2023CharacterAI,
  author  = {ZenML Team},
  title   = {Character.AI Scaling to 30k+ Messages per Second},
  journal = {ZenML Blog},
  year    = {2023},
  url     = {https://zenml.io}
}

@article{Author2024AWQ,
  author  = {Author, Placeholder},
  title   = {Efficient Weight Quantization for LLMs (AWQ)},
  journal = {arXiv preprint arXiv:2401.xxxxx},
  year    = {2024},
  url     = {https://arxiv.org}
}

@article{Author2024NonDeterminism,
  author  = {Author, Placeholder},
  title   = {Operational Challenges of Non-Deterministic LLM Outputs},
  journal = {arXiv preprint arXiv:2402.xxxxx},
  year    = {2024},
  url     = {https://arxiv.org}
}

@article{Placeholder2022GalacticaNote,
  author  = {Placeholder},
  title   = {Additional Commentary on Meta’s Galactica Failure},
  journal = {Blog/Tech Note},
  year    = {2022}
}

@article{LangChain2023Framework,
  author  = {Chase, Harrison and contributors},
  title   = {LangChain: Building Applications with Language Models},
  journal = {GitHub Repository / Documentation},
  year    = {2023},
  url     = {https://github.com/hwchase17/langchain}
}

@article{LangGraph2024Framework,
  author  = {LangChain Team},
  title   = {LangGraph: Declarative Graph-Based Multi-Agent Orchestration},
  journal = {Documentation / Blog},
  year    = {2024},
  url     = {https://docs.langchain.com/docs/langgraph}
}

@article{CrewAI2024Framework,
  author  = {CrewAI Contributors},
  title   = {CrewAI: Multi-Agent Orchestration Framework},
  journal = {GitHub Repository},
  year    = {2024},
  url     = {https://github.com/joaomdmoura/crewAI}
}

@article{neptune2023rag,
  title   = {Title Placeholder},
  author  = {Author Placeholder},
  journal = {Journal Placeholder},
  year    = {2023}
}

@misc{cloud2023ragas,
  author = {Author, A.},
  title  = {Title of the RAGAS Paper or Resource},
  year   = {2023},
  note   = {Accessed: 2024-06-01},
  url    = {https://example.com}
}

@misc{cloud2023eval,
  title  = {Title Placeholder},
  author = {Author Placeholder},
  year   = {2023},
  note   = {Add full details here}
}

@misc{Milvus2023,
  title  = {Milvus: Open-Source Vector Database},
  year   = {2023},
  author = {todo},
  key    = {todo},
  note   = {\url{https://milvus.io/}}
}

@article{Zilliz2023,
  author  = {Author Name},
  title   = {Title of the Article},
  journal = {Journal Name},
  year    = {2023},
  volume  = {1},
  number  = {1},
  pages   = {1--10},
  doi     = {10.0000/exampledoi},
  note    = {Add correct details}
}

@misc{AICOM2023,
  author = {Author Unknown},
  title  = {Title Unknown},
  year   = {2023},
  note   = {Placeholder entry for missing citation}
}
@article{Lewis2020RAGb,
  author  = {Patrick Lewis and others},
  title   = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  journal = {arXiv preprint arXiv:2005.11401},
  year    = {2020},
  url     = {https://arxiv.org/abs/2005.11401}
}

@misc{Devto2023,
  title  = {Title of the Devto 2023 Article},
  author = {Author Name},
  year   = {2023},
  note   = {Available at: https://dev.to/your-article-link}
}

@article{Ke4e1qarpukhin2020DPR,
  title   = { Dense Passage Retrieval for Open-Domain Question Answering },
  author  = { Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau },
  journal = { arXiv preprint arXiv:2004.04906 },
  year    = { 2020 }
}

@inproceedings{Johnson2019FAISS,
  title     = {Billion-scale similarity search with GPUs},
  author    = {Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  booktitle = {IEEE Transactions on Big Data},
  year      = {2019},
  publisher = {IEEE},
  doi       = {10.1109/TBDATA.2019.2921572}
}

@article{Malkov2018HNSW,
  title     = {Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs},
  author    = {Malkov, Yu A and Yashunin, Dmitry A},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume    = {42},
  number    = {4},
  pages     = {824--836},
  year      = {2020},
  publisher = {IEEE},
  doi       = {10.1109/TPAMI.2018.2889473}
}

@inproceedings{Jegou2011PQ,
  title     = {Product quantization for nearest neighbor search},
  author    = {J{\'e}gou, Herv{\'e} and Douze, Matthijs and Schmid, Cordelia},
  booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume    = {33},
  number    = {1},
  pages     = {117--128},
  year      = {2011},
  publisher = {IEEE},
  doi       = {10.1109/TPAMI.2010.57}
}

@article{Thakur2021BEIR,
  title   = { BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models },
  author  = { Thakur, Nandan and Reimers, Nils and Daxenberger, Johannes and Gurevych, Iryna },
  journal = { Proceedings of NeurIPS },
  year    = { 2021 }
}

@article{Zhan2021ColBERTv2,
  title   = { ColBERTv2: Effective and efficient retrieval via lightweight late interaction },
  author  = { Zhan, Jingtao and Mao, Jiaxin and Guo, Jiafeng and Zhai, ChengXiang },
  journal = { arXiv preprint arXiv:2112.01488 },
  year    = { 2021 }
}

@article{Lin2021SPLADE,
  title   = { Pyserini: An easy-to-use toolkit for reproducible information retrieval research },
  author  = { Lin, Jimmy and Ma, Xueguang and Lin, Sheng-Chieh and Yang, Jheng-Hong and Pradeep, Ronak and Nogueira, Rodrigo },
  journal = { Proceedings of SIGIR },
  year    = { 2021 }
}

@article{Asai2020MultiHop,
  title   = { Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering },
  author  = { Asai, Akari and Hashimoto, Tatsunori and Hajishirzi, Hannaneh and Yih, Wen-tau and Richardson, Matthew },
  journal = { arXiv preprint arXiv:1911.10470 },
  year    = { 2020 }
}

@article{Nakano2021WebGPT,
  title   = { WebGPT: Browser-assisted question-answering with human feedback },
  author  = { Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and others },
  journal = { arXiv preprint arXiv:2112.09332 },
  year    = { 2021 }
}

@misc{Pryon2023,
  author = {Pryon Inc.},
  title  = {Pryon RAG Platform Documentation},
  year   = {2023},
  note   = {Accessed: 2023-12-01},
  url    = {https://www.pryon.com/solutions/rag}
}

@article{Guu2020REALM,
  title   = { REALM: Retrieval-Augmented Language Model Pre-Training },
  author  = { Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Ming-Wei },
  journal = { arXiv preprint arXiv:2002.08909 },
  year    = { 2020 }
}

@article{Izacard2020Fusion,
  title   = { Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering },
  author  = { Izacard, Gautier and Grave, Edouard },
  journal = { arXiv preprint arXiv:2007.01282 },
  year    = { 2020 }
}

@article{Borgeaud2022RETRO,
  title   = { Improving language models by retrieving from trillions of tokens },
  author  = { Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katherine and Driessche, George van den and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others },
  journal = { Proceedings of ICML },
  year    = { 2022 }
}

@article{Pinecone2023RAG,
  title   = { What is Retrieval-Augmented Generation (RAG)? },
  author  = { Pinecone Systems Inc. },
  journal = { Pinecone Documentation },
  year    = { 2023 }
}

@article{AWS2023NeuralSparse,
  title   = { Neural Sparse Retrieval at Scale },
  author  = { AWS AI Labs },
  journal = { AWS AI Blog },
  year    = { 2023 }
}

@misc{tensorrt-llm-github,
  title        = {TensorRT-LLM},
  howpublished = {\url{https://github.com/NVIDIA/TensorRT-LLM}},
  author       = {todo},
  key          = {todo},
  note         = {Accessed: 2024-06-01}
}

@misc{switch-transformers,
  title  = {Switch Transformers},
  author = {Author, A.},
  year   = {2021},
  note   = {Placeholder entry. Update with correct bibliographic information.}
}

@misc{kv-quant,
  title  = {Placeholder Title},
  author = {Author, A.},
  year   = {2024},
  note   = {Add correct details for kv-quant}
}

@misc{gptq,
  title  = {GPTQ: An Efficient Quantization Method for LLMs},
  author = {Author, A.},
  year   = {2023},
  note   = {URL or more details here}
}

@misc{fp8-training,
  title  = {FP8 Training: Placeholder Title},
  author = {Author, A.},
  year   = {2024},
  note   = {Add full details here}
}

@misc{flashattention-v2,
  title  = {FlashAttention-v2},
  author = {Author, A.},
  year   = {2023},
  note   = {URL: https://github.com/Dao-AILab/flash-attention}
}

@article{expert-parallel,
  author  = {Author, A.},
  title   = {Title of the Expert Parallel Paper},
  journal = {Journal Name},
  year    = {2024},
  volume  = {1},
  number  = {1},
  pages   = {1--10}
}

@misc{gpt-inference,
  title  = {GPT Inference: Placeholder Title},
  author = {Author, A.},
  year   = {2024},
  note   = {Add full details here}
}

@misc{encoder-ops-2,
  title  = {Title of the Encoder Ops Reference},
  author = {Author, A.},
  year   = {2024},
  note   = {Add full details here}
}

@article{int8-quantization,
  title   = {Title of the Article},
  author  = {Author, A.},
  journal = {Journal Name},
  year    = {2024},
  note    = {Replace with correct details}
}

@article{bert-original,
  author  = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  title   = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  journal = {arXiv preprint arXiv:1810.04805},
  year    = {2018}
}

@article{moe-inference,
  title   = {Title Placeholder},
  author  = {Author Placeholder},
  journal = {Journal Placeholder},
  year    = {2024}
}

@article{paged-attention,
  title   = {Title Placeholder for Paged Attention},
  author  = {Author Placeholder},
  journal = {Journal Placeholder},
  year    = {2024},
  note    = {Replace with correct details}
}

@misc{attention-kv-cache,
  author = {Author Unknown},
  title  = {Attention KV Cache},
  year   = {2024},
  note   = {Placeholder entry for missing citation}
}

@misc{awq,
  title  = {Placeholder for missing AWQ reference},
  author = {Author, A.},
  year   = {2024},
  note   = {Please update this entry with the correct bibliographic information.}
}

@inproceedings{Vaswani2017attention,
  title     = {Attention Is All You Need},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {30},
  year      = {2017}
}

@article{ouyang2022instructgpt,
  title   = {Training Language Models to Follow Instructions with Human Feedback},
  author  = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal = {arXiv preprint arXiv:2203.02155},
  year    = {2022}
}

@article{bai2022constitutional,
  title   = {Constitutional AI: Harmlessness from AI Feedback},
  author  = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Chad and others},
  journal = {arXiv preprint arXiv:2212.08073},
  year    = {2022}
}

@article{touvron2023llama,
  title   = {LLaMA: Open and Efficient Foundation Language Models},
  author  = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal = {arXiv preprint arXiv:2302.13971},
  year    = {2023}
}

@article{black2022gptneox,
  title   = {GPT-NeoX-20B: An Open-Source Autoregressive Language Model},
  author  = {Black, Sid and Gao, Stella Biderman and Golding, Laurence and Hoppe, Horace and Foster, Eric and Phang, Jason and He, Anish and Thite, Diego and Nabeshima, Jaden and Presser, Shawn and Leahy, Connor},
  journal = {arXiv preprint arXiv:2204.06745},
  year    = {2022}
}

@article{alabdulmohsin2023falcon,
  title   = {Falcon-40B: An Open Large Language Model with State-of-the-Art Performance},
  author  = {Alabdulmohsin, Ibrahim and Tay, Yi and Metzler, Donald and Alfonseca, Enrique and Schuster, Tal and Wallace, Eric and others},
  journal = {arXiv preprint arXiv:2306.01116},
  year    = {2023}
}

@inproceedings{johnson2017faiss,
  title     = {Billion-Scale Similarity Search with GPUs},
  author    = {Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  booktitle = {IEEE Transactions on Big Data},
  volume    = {7},
  number    = {3},
  pages     = {535--547},
  year      = {2017}
}

@article{su2021rope,
  title   = {RoFormer: Enhanced Transformer with Rotary Position Embedding},
  author  = {Su, Jianlin and Lu, Yu and Pan, Shengfeng and Wei, Bo and Liu, Yunfeng},
  journal = {arXiv preprint arXiv:2104.09864},
  year    = {2021}
}

@misc{langchainDocs,
  author       = {LangChain},
  title        = {LangChain Documentation},
  year         = {2023},
  howpublished = {\url{https://docs.langchain.com/}}
}

@misc{llamaindexDocs,
  author       = {LlamaIndex},
  title        = {LlamaIndex Documentation},
  year         = {2023},
  howpublished = {\url{https://gpt-index.readthedocs.io/}}
}

@misc{mlflow,
  author       = {{MLflow}},
  title        = {MLflow Documentation},
  year         = {2023},
  howpublished = {\url{https://mlflow.org/}}
}

@misc{wandb,
  author       = {{Weights \& Biases}},
  title        = {Weights \& Biases Documentation},
  year         = {2023},
  howpublished = {\url{https://docs.wandb.ai/}}
}

@misc{vllm,
  author       = {vLLM Team},
  title        = {vLLM: Easy, Fast, and Cheap LLM Serving},
  year         = {2023},
  howpublished = {\url{https://vllm.ai/}}
}

@misc{tgi,
  author       = {{Hugging Face}},
  title        = {Text Generation Inference (TGI)},
  year         = {2023},
  howpublished = {\url{https://huggingface.co/docs/text-generation-inference}}
}

@misc{tensorrtllm,
  author       = {NVIDIA},
  title        = {TensorRT-LLM},
  year         = {2023},
  howpublished = {\url{https://developer.nvidia.com/tensorrt-llm}}
}

@misc{prometheus,
  author       = {Prometheus Authors},
  title        = {Prometheus Monitoring System},
  year         = {2023},
  howpublished = {\url{https://prometheus.io/}}
}

@misc{grafana,
  author       = {Grafana Labs},
  title        = {Grafana: The Open Observability Platform},
  year         = {2023},
  howpublished = {\url{https://grafana.com/}}
}

@misc{langfuse,
  author       = {LangFuse},
  title        = {LangFuse Documentation},
  year         = {2023},
  howpublished = {\url{https://langfuse.com/docs}}
}

@misc{fused-kernels,
  title  = {Title of the Fused Kernels Reference},
  author = {Author Name},
  year   = {2024},
  note   = {Accessed: 2024-06-01}
}
@inproceedings{johnson2019billion,
  title     = {Billion-scale similarity search with GPUs},
  author    = {Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  booktitle = {IEEE Transactions on Big Data},
  year      = {2019},
  publisher = {IEEE}
}

@online{openai_structured_outputs_docs,
  title        = {Structured model outputs},
  organization = {OpenAI},
  url          = {https://platform.openai.com/docs/guides/structured-outputs},
  urldate      = {2025-12-30},
  note         = {OpenAI API documentation}
}

@online{openai_structured_outputs_blog,
  title        = {Introducing Structured Outputs in the API},
  organization = {OpenAI},
  year         = {2024},
  month        = aug,
  url          = {https://openai.com/index/introducing-structured-outputs-in-the-api/},
  urldate      = {2025-12-30}
}

@online{openai_function_calling_docs,
  title        = {Function calling},
  organization = {OpenAI},
  url          = {https://platform.openai.com/docs/guides/function-calling},
  urldate      = {2025-12-30},
  note         = {OpenAI API documentation}
}

@online{openai_evals,
  title        = {Evals},
  organization = {OpenAI},
  url          = {https://github.com/openai/evals},
  urldate      = {2025-12-30},
  note         = {Open-source evaluation framework and registry}
}

@article{helm,
  title   = {Holistic Evaluation of Language Models},
  author  = {Liang, Percy and others},
  journal = {arXiv preprint arXiv:2211.09110},
  year    = {2022},
  url     = {https://arxiv.org/abs/2211.09110},
  urldate = {2025-12-30}
}

@article{pagedattention_vllm,
  title   = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author  = {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph E. and Zhang, Hao and Stoica, Ion},
  journal = {arXiv preprint arXiv:2309.06180},
  year    = {2023},
  url     = {https://arxiv.org/abs/2309.06180},
  urldate = {2025-12-30}
}

@online{owasp_llm_top10,
  title        = {OWASP Top 10 for Large Language Model Applications},
  organization = {OWASP},
  url          = {https://owasp.org/www-project-top-10-for-large-language-model-applications/},
  urldate      = {2025-12-30},
  note         = {Project page (see versioned releases for PDFs)}
}

@online{nist_ai_rmf,
  title        = {Artificial Intelligence Risk Management Framework (AI RMF 1.0)},
  organization = {National Institute of Standards and Technology (NIST)},
  year         = {2023},
  url          = {https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf},
  urldate      = {2025-12-30},
  note         = {NIST AI 100-1}
}

% ======================================================================
% Bib additions for Chapter 3 (Infrastructure & Environment)
% Append to references.bib (biblatex + biber)
% Generated: 2025-12-30
% ======================================================================

@article{pagedattention_paper,
  title      = {Efficient Memory Management for Large Language Model Serving with {PagedAttention}},
  author     = {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph E. and Zhang, Hao and Stoica, Ion},
  year       = {2023},
  eprint     = {2309.06180},
  eprinttype = {arxiv},
  url        = {https://arxiv.org/abs/2309.06180}
}

@online{tensorrtllm_docs,
  title        = {NVIDIA TensorRT-LLM Documentation},
  organization = {NVIDIA},
  url          = {https://docs.nvidia.com/tensorrt-llm/index.html},
  urldate      = {2025-12-30}
}

@online{triton_docs,
  title        = {NVIDIA Triton Inference Server Documentation},
  organization = {NVIDIA},
  url          = {https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/index.html},
  urldate      = {2025-12-30}
}

@online{nvidia_gpu_operator_docs,
  title        = {About the NVIDIA GPU Operator},
  organization = {NVIDIA},
  url          = {https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/index.html},
  urldate      = {2025-12-30}
}

@online{gke_gpu_operator_guide,
  title        = {Manage the GPU Stack with the NVIDIA GPU Operator on {GKE}},
  organization = {Google Cloud},
  url          = {https://docs.cloud.google.com/kubernetes-engine/docs/how-to/gpu-operator},
  urldate      = {2025-12-30}
}

@online{k8s_architecture,
  title        = {Kubernetes Cluster Architecture},
  organization = {Kubernetes Documentation},
  url          = {https://kubernetes.io/docs/concepts/architecture/},
  urldate      = {2025-12-30}
}

@online{k8s_components,
  title        = {Kubernetes Components},
  organization = {Kubernetes Documentation},
  url          = {https://kubernetes.io/docs/concepts/overview/components/},
  urldate      = {2025-12-30}
}

@online{k8s_control_plane_comm,
  title        = {Communication between Nodes and the Control Plane},
  organization = {Kubernetes Documentation},
  url          = {https://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/},
  urldate      = {2025-12-30}
}

@online{terraform_modules,
  title        = {Modules Overview},
  organization = {HashiCorp Terraform Documentation},
  url          = {https://developer.hashicorp.com/terraform/tutorials/modules/module},
  urldate      = {2025-12-30}
}

@online{terraform_recommended_practices,
  title        = {Learn Terraform Recommended Practices},
  organization = {HashiCorp},
  url          = {https://developer.hashicorp.com/terraform/cloud-docs/recommended-practices},
  urldate      = {2025-12-30}
}

@online{aws_terraform_structure,
  title        = {Best Practices for Code Base Structure and Organization (Terraform on AWS)},
  organization = {Amazon Web Services},
  url          = {https://docs.aws.amazon.com/prescriptive-guidance/latest/terraform-aws-provider-best-practices/structure.html},
  urldate      = {2025-12-30}
}

@online{aws_neuron_arch_guide,
  title        = {Trainium/Inferentia2 Architecture Guide for {NKI}},
  organization = {AWS Neuron Documentation},
  url          = {https://awsdocs-neuron.readthedocs-hosted.com/en/latest/nki/guides/architecture/trainium_inferentia2_arch.html},
  urldate      = {2025-12-30}
}

@online{aws_trainium2_arch,
  title        = {Trainium2 Architecture},
  organization = {AWS Neuron Documentation},
  url          = {https://awsdocs-neuron.readthedocs-hosted.com/en/latest/about-neuron/arch/neuron-hardware/trainium2.html},
  urldate      = {2025-12-30}
}

@online{aws_inferentia_overview,
  title        = {AWS Inferentia},
  organization = {Amazon Web Services},
  url          = {https://aws.amazon.com/ai/machine-learning/inferentia/},
  urldate      = {2025-12-30}
}

% ======================================================================
% ch04_bib_additions.bib
% Add these entries to your main references.bib (biblatex + biber).
% Generated: 2025-12-30
% ======================================================================

@online{slsa_about,
  title        = {SLSA: Supply-chain Levels for Software Artifacts},
  organization = {SLSA / OpenSSF / Linux Foundation},
  url          = {https://slsa.dev/},
  urldate      = {2025-12-30}
}

@online{slsa_levels,
  title        = {SLSA Levels and Tracks},
  organization = {SLSA / OpenSSF / Linux Foundation},
  url          = {https://slsa.dev/spec/v1.0/levels},
  urldate      = {2025-12-30}
}

@online{sigstore_cosign,
  title        = {cosign: Container Signing, Verification and Transparency (Sigstore)},
  organization = {Sigstore},
  url          = {https://docs.sigstore.dev/cosign/},
  urldate      = {2025-12-30}
}

@online{cosign_attestations,
  title        = {Cosign In-Toto Attestations},
  organization = {Sigstore},
  url          = {https://docs.sigstore.dev/cosign/verifying/attestation/},
  urldate      = {2025-12-30}
}

@online{gha_security,
  title        = {Security for GitHub Actions},
  organization = {GitHub Docs},
  url          = {https://docs.github.com/actions/security-for-github-actions},
  urldate      = {2025-12-30}
}

@online{gha_secure_use,
  title        = {Secure Use Reference (GitHub Actions)},
  organization = {GitHub Docs},
  url          = {https://docs.github.com/en/actions/reference/security/secure-use},
  urldate      = {2025-12-30}
}

@online{gha_oidc_concepts,
  title        = {OpenID Connect (OIDC) in GitHub Actions},
  organization = {GitHub Docs},
  url          = {https://docs.github.com/en/actions/concepts/security/openid-connect},
  urldate      = {2025-12-30}
}

@online{gha_oidc_cloud,
  title        = {Configuring OpenID Connect in Cloud Providers (GitHub Actions)},
  organization = {GitHub Docs},
  url          = {https://docs.github.com/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-cloud-providers},
  urldate      = {2025-12-30}
}

@online{argo_rollouts_overview,
  title        = {Argo Rollouts: Kubernetes Progressive Delivery Controller},
  organization = {Argo Project},
  url          = {https://argoproj.github.io/rollouts/},
  urldate      = {2025-12-30}
}

@online{argo_rollouts_canary,
  title        = {Argo Rollouts Canary Deployment Strategy},
  organization = {Argo Rollouts Documentation},
  url          = {https://argo-rollouts.readthedocs.io/en/stable/features/canary/},
  urldate      = {2025-12-30}
}

@online{argo_rollouts_bluegreen,
  title        = {Argo Rollouts Blue-Green Deployment Strategy},
  organization = {Argo Rollouts Documentation},
  url          = {https://argo-rollouts.readthedocs.io/en/stable/features/bluegreen/},
  urldate      = {2025-12-30}
}

@online{openai_evals_cookbook,
  title        = {Getting Started with OpenAI Evals},
  organization = {OpenAI Cookbook},
  url          = {https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals},
  urldate      = {2025-12-30}
}

@online{langsmith_evaluation,
  title        = {LangSmith Evaluation Documentation},
  organization = {LangChain},
  url          = {https://docs.langchain.com/langsmith/evaluation},
  urldate      = {2025-12-30}
}

@online{mlflow_model_registry,
  title        = {MLflow Model Registry},
  organization = {MLflow},
  url          = {https://mlflow.org/docs/latest/ml/model-registry/},
  urldate      = {2025-12-30}
}

@online{mlflow_model_registry_workflow,
  title        = {MLflow Model Registry Workflows},
  organization = {MLflow},
  url          = {https://mlflow.org/docs/latest/ml/model-registry/workflow/},
  urldate      = {2025-12-30}
}

% ============================================================
% Chapter 5 (Observability) — BibLaTeX additions
% Append these entries to your main references.bib
% ============================================================

@online{otel_traces,
  title        = {Traces},
  organization = {OpenTelemetry},
  year         = {2025},
  url          = {https://opentelemetry.io/docs/concepts/signals/traces/},
  urldate      = {2025-12-30}
}

@online{otel_logs_concepts,
  title        = {OpenTelemetry Logs},
  organization = {OpenTelemetry},
  year         = {2025},
  url          = {https://opentelemetry.io/docs/concepts/signals/logs/},
  urldate      = {2025-12-30}
}

@online{otel_spec,
  title        = {OpenTelemetry Specification},
  organization = {OpenTelemetry},
  year         = {2025},
  url          = {https://opentelemetry.io/docs/specs/otel/},
  urldate      = {2025-12-30}
}

@online{otel_collector,
  title        = {OpenTelemetry Collector},
  organization = {OpenTelemetry},
  year         = {2025},
  url          = {https://opentelemetry.io/docs/collector/},
  urldate      = {2025-12-30}
}

@online{openmetrics_spec,
  title        = {OpenMetrics 1.0 Specification},
  organization = {Prometheus},
  year         = {2020},
  url          = {https://prometheus.io/docs/specs/om/open_metrics_spec/},
  urldate      = {2025-12-30}
}

@online{prometheus_instrumentation,
  title        = {Instrumentation},
  organization = {Prometheus},
  year         = {2025},
  url          = {https://prometheus.io/docs/practices/instrumentation/},
  urldate      = {2025-12-30}
}

@online{prometheus_clientlibs,
  title        = {Client libraries},
  organization = {Prometheus},
  year         = {2025},
  url          = {https://prometheus.io/docs/instrumenting/clientlibs/},
  urldate      = {2025-12-30}
}

@online{grafana_dashboards,
  title        = {Dashboards},
  organization = {Grafana Labs},
  year         = {2025},
  url          = {https://grafana.com/docs/grafana/latest/visualizations/dashboards/},
  urldate      = {2025-12-30}
}

@online{langsmith_home,
  title        = {LangSmith Documentation},
  organization = {LangChain},
  year         = {2025},
  url          = {https://docs.langchain.com/langsmith/home},
  urldate      = {2025-12-30}
}

@online{langsmith_online_evals,
  title        = {Set up online evaluators},
  organization = {LangChain},
  year         = {2025},
  url          = {https://docs.langchain.com/langsmith/online-evaluations},
  urldate      = {2025-12-30}
}

@online{langfuse_obs_overview,
  title        = {LLM Observability \& Application Tracing (Overview)},
  organization = {Langfuse},
  year         = {2025},
  url          = {https://langfuse.com/docs/observability/overview},
  urldate      = {2025-12-30}
}

@online{langfuse_docs,
  title        = {Langfuse Documentation},
  organization = {Langfuse},
  year         = {2025},
  url          = {https://langfuse.com/docs},
  urldate      = {2025-12-30}
}

@online{langfuse_data_model,
  title        = {Tracing Data Model in Langfuse},
  organization = {Langfuse},
  year         = {2025},
  url          = {https://langfuse.com/docs/observability/data-model},
  urldate      = {2025-12-30}
}

@online{langfuse_eval_overview,
  title        = {Evaluation Overview},
  organization = {Langfuse},
  year         = {2025},
  url          = {https://langfuse.com/docs/evaluation/overview},
  urldate      = {2025-12-30}
}

@online{arize_phoenix_docs,
  title        = {Arize Phoenix Documentation},
  organization = {Arize AI},
  year         = {2025},
  url          = {https://arize.com/docs/phoenix},
  urldate      = {2025-12-30}
}

% ======================================================================
% ch06_bib_additions.bib
% BibLaTeX entries added for Chapter 6 (Scaling)
% ======================================================================

@article{vllm_pagedattention,
  title      = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author     = {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph E. and Zhang, Hao and Stoica, Ion},
  year       = {2023},
  journal    = {arXiv},
  eprint     = {2309.06180},
  eprinttype = {arxiv},
  url        = {https://arxiv.org/abs/2309.06180}
}

@article{speculative_decoding,
  title      = {Fast Inference from Transformers via Speculative Decoding},
  author     = {Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  year       = {2022},
  journal    = {arXiv},
  eprint     = {2211.17192},
  eprinttype = {arxiv},
  url        = {https://arxiv.org/abs/2211.17192}
}

@article{vaswani2017_attention,
  title      = {Attention Is All You Need},
  author     = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  year       = {2017},
  journal    = {arXiv},
  eprint     = {1706.03762},
  eprinttype = {arxiv},
  url        = {https://arxiv.org/abs/1706.03762}
}

@article{frugalgpt_2023,
  title      = {FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance},
  author     = {Chen, Lingjiao and Zaharia, Matei and Zou, James},
  year       = {2023},
  journal    = {arXiv},
  eprint     = {2305.05176},
  eprinttype = {arxiv},
  url        = {https://arxiv.org/abs/2305.05176}
}

@article{megatron_lm_2019,
  title      = {Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
  author     = {Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  year       = {2019},
  journal    = {arXiv},
  eprint     = {1909.08053},
  eprinttype = {arxiv},
  url        = {https://arxiv.org/abs/1909.08053}
}

@article{awq_2023,
  title      = {AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration},
  author     = {Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Chen, Wei-Ming and Wang, Wei-Chen and Xiao, Guangxuan and Dang, Xingyu and Gan, Chuang and Han, Song},
  year       = {2023},
  journal    = {arXiv},
  eprint     = {2306.00978},
  eprinttype = {arxiv},
  url        = {https://arxiv.org/abs/2306.00978}
}


@article{vattention_2024,
  title      = {vAttention: Dynamic Memory Management for Serving LLMs without PagedAttention},
  author     = {Prabhu, Ramya and Nayak, Ajay and Mohan, Jayashree and Ramjee, Ramachandran and Panwar, Ashish},
  year       = {2024},
  journal    = {arXiv},
  eprint     = {2405.04437},
  eprinttype = {arxiv},
  url        = {https://arxiv.org/abs/2405.04437}
}

@online{tensorrt_llm_docs,
  title        = {NVIDIA TensorRT-LLM Documentation},
  organization = {NVIDIA},
  url          = {https://docs.nvidia.com/tensorrt-llm/index.html},
  urldate      = {2025-12-30}
}

@online{nvidia_mig_guide,
  title        = {NVIDIA Multi-Instance GPU (MIG) User Guide},
  organization = {NVIDIA},
  url          = {https://docs.nvidia.com/datacenter/tesla/mig-user-guide/},
  urldate      = {2025-12-30}
}

@online{k8s_hpa_docs,
  title        = {Horizontal Pod Autoscaling},
  organization = {Kubernetes Documentation},
  url          = {https://kubernetes.io/docs/concepts/workloads/autoscaling/horizontal-pod-autoscale/},
  urldate      = {2025-12-30}
}

@online{keda_docs,
  title        = {KEDA: Kubernetes Event-driven Autoscaling},
  organization = {KEDA},
  url          = {https://keda.sh/},
  urldate      = {2025-12-30}
}

@misc{tgi_docs,
  title        = {Benchmarking Text Generation Inference},
  author       = {Thomas, Derek},
  year         = {2024},
  howpublished = {Hugging Face Blog},
  url          = {https://huggingface.co/blog/tgi-benchmarking}
}

% ==========================================================
% Chapter 7 bib additions (append to references.bib)
% ==========================================================

@article{Dao2022FlashAttention,
  title         = {FlashAttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author        = {Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  year          = {2022},
  eprint        = {2205.14135},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2205.14135}
}

@article{Dao2023FlashAttention2,
  title         = {FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning},
  author        = {Dao, Tri},
  year          = {2023},
  eprint        = {2307.08691},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2307.08691}
}

@article{Chen2023SpeculativeSampling,
  title         = {Accelerating Large Language Model Decoding with Speculative Sampling},
  author        = {Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John},
  year          = {2023},
  eprint        = {2302.01318},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2302.01318}
}

% ============================================================
% Chapter 8 (RAG) – Bib additions (append to references.bib)
% Generated: 2025-12-30
% ============================================================

@article{robertson2009bm25,
  title   = {The Probabilistic Relevance Framework: {BM25} and Beyond},
  author  = {Robertson, Stephen and Zaragoza, Hugo},
  journal = {Foundations and Trends{\textregistered} in Information Retrieval},
  year    = {2009},
  volume  = {3},
  number  = {4},
  pages   = {333--389},
  doi     = {10.1561/1500000019}
}

@inproceedings{khattab2020colbert,
  title     = {{ColBERT}: Efficient and Effective Passage Search via Contextualized Late Interaction over {BERT}},
  author    = {Khattab, Omar and Zaharia, Matei},
  booktitle = {Proceedings of the 43rd International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
  year      = {2020},
  doi       = {10.1145/3397271.3401075},
  url       = {https://arxiv.org/abs/2004.12832},
  urldate   = {2025-12-30}
}

@inproceedings{cormack2009rrf,
  title     = {Reciprocal Rank Fusion outperforms {Condorcet} and Individual Rank Learning Methods},
  author    = {Cormack, Gordon V. and Clarke, Charles L. A. and B{\"u}ttcher, Stefan},
  booktitle = {Proceedings of the 32nd International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
  year      = {2009},
  pages     = {758--759},
  doi       = {10.1145/1571941.1572114},
  url       = {https://cormack.uwaterloo.ca/cormacksigir09-rrf.pdf},
  urldate   = {2025-12-30}
}

@inproceedings{gao2023hyde,
  title     = {Precise Zero-Shot Dense Retrieval without Relevance Labels},
  author    = {Gao, Luyu and Ma, Xueguang and Lin, Jimmy and Callan, Jamie},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year      = {2023},
  url       = {https://aclanthology.org/2023.acl-long.99/},
  urldate   = {2025-12-30}
}

@article{johnson2017billion,
  title         = {Billion-scale similarity search with {GPUs}},
  author        = {Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal       = {arXiv},
  year          = {2017},
  eprint        = {1702.08734},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1702.08734},
  urldate       = {2025-12-30}
}

@online{faiss_blog,
  title   = {{Faiss}: A library for efficient similarity search},
  author  = {{Meta Engineering}},
  year    = {2017},
  url     = {https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/},
  urldate = {2025-12-30}
}

@online{faiss_github,
  title   = {{facebookresearch/faiss}: A library for efficient similarity search and clustering of dense vectors},
  author  = {{Meta (FAIR)}},
  year    = {2025},
  url     = {https://github.com/facebookresearch/faiss},
  urldate = {2025-12-30}
}

@online{pinecone_hybrid_docs,
  title   = {Hybrid search},
  author  = {{Pinecone}},
  year    = {2025},
  url     = {https://docs.pinecone.io/guides/search/hybrid-search},
  urldate = {2025-12-30}
}

@online{weaviate_hybrid_docs,
  title   = {Hybrid search},
  author  = {{Weaviate}},
  year    = {2025},
  url     = {https://docs.weaviate.io/weaviate/search/hybrid},
  urldate = {2025-12-30}
}

@online{langchain_retrievers_docs,
  title   = {Retrievers},
  author  = {{LangChain}},
  year    = {2025},
  url     = {https://docs.langchain.com/oss/python/integrations/retrievers},
  urldate = {2025-12-30}
}

@online{llamaindex_rag_docs,
  title   = {Retrieval Augmented Generation ({RAG})},
  author  = {{LlamaIndex}},
  year    = {2025},
  url     = {https://developers.llamaindex.ai/typescript/framework/tutorials/rag/},
  urldate = {2025-12-30}
}

@inproceedings{Karpukhin2020DPR,
  title     = {Dense Passage Retrieval for Open-Domain Question Answering},
  author    = {Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2020},
  pages     = {6769--6781},
  url       = {https://aclanthology.org/2020.emnlp-main.550/},
  urldate   = {2025-12-30}
}

% ======================================================================
% Chapter 9 bib additions (multi-agent orchestration)
% Append to your main references.bib (biblatex+biber)
% Generated: 2025-12-31
% ======================================================================

@article{react,
  title        = {ReAct: Synergizing Reasoning and Acting in Language Models},
  author       = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  year         = {2022},
  eprint       = {2210.03629},
  eprinttype   = {arxiv},
  primaryclass = {cs.CL},
  url          = {https://arxiv.org/abs/2210.03629}
}

@article{toolformer,
  title        = {Toolformer: Language Models Can Teach Themselves to Use Tools},
  author       = {Schick, Timo and Dwivedi-Yu, Jane and Dess{\`i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  year         = {2023},
  eprint       = {2302.04761},
  eprinttype   = {arxiv},
  primaryclass = {cs.CL},
  url          = {https://arxiv.org/abs/2302.04761}
}

@article{autogen,
  title        = {AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation},
  author       = {Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Li, Beibin and Zhu, Erkang and Jiang, Li and Zhang, Xiaoyun and Zhang, Shaokun and Liu, Jiale and Awadallah, Ahmed Hassan and White, Ryen W. and Burger, Doug and Wang, Chi},
  year         = {2023},
  eprint       = {2308.08155},
  eprinttype   = {arxiv},
  primaryclass = {cs.CL},
  url          = {https://arxiv.org/abs/2308.08155}
}

@online{langgraph_overview,
  title        = {LangGraph Overview},
  organization = {LangChain},
  url          = {https://docs.langchain.com/oss/python/langgraph/overview},
  urldate      = {2025-12-31}
}

@online{langgraph_graph_api,
  title        = {Graph API Overview},
  organization = {LangChain},
  url          = {https://docs.langchain.com/oss/python/langgraph/graph-api},
  urldate      = {2025-12-31}
}

@online{temporal_workflows_docs,
  title        = {Temporal Workflow},
  organization = {Temporal Technologies},
  url          = {https://docs.temporal.io/workflows},
  urldate      = {2025-12-31}
}

@online{temporal_workflow_execution,
  title        = {Temporal Workflow Execution Overview},
  organization = {Temporal Technologies},
  url          = {https://docs.temporal.io/workflow-execution},
  urldate      = {2025-12-31}
}

@online{semantic_kernel_agent_orchestration,
  title        = {Semantic Kernel Agent Orchestration},
  organization = {Microsoft Learn},
  year         = {2025},
  url          = {https://learn.microsoft.com/en-us/semantic-kernel/frameworks/agent/agent-orchestration/},
  urldate      = {2025-12-31}
}

@online{langsmith_eval_docs,
  title        = {LangSmith Evaluation},
  organization = {LangChain},
  url          = {https://docs.langchain.com/langsmith/evaluation},
  urldate      = {2025-12-31}
}

% =========================
% Chapter 10 bib additions
% =========================

@article{helm_arxiv,
  author  = {Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and Newman, Benjamin and Yuan, Binhang and Yan, Bobby and Zhang, Ce and Cosgrove, Christian and Manning, Christopher D. and R{\'e}, Christopher and others},
  title   = {Holistic Evaluation of Language Models},
  journal = {arXiv preprint arXiv:2211.09110},
  year    = {2022},
  url     = {https://arxiv.org/abs/2211.09110},
  urldate = {2025-12-31}
}

@online{helm_site,
  author  = {{Center for Research on Foundation Models (CRFM), Stanford University}},
  title   = {The Holistic Evaluation of Language Models (HELM)},
  year    = {2024},
  url     = {https://crfm.stanford.edu/helm/},
  urldate = {2025-12-31}
}

@article{ragas_arxiv,
  author  = {Es, Shahul and James, Jithin and Espinosa-Anke, Luis and Schockaert, Steven},
  title   = {{RAGAS}: Automated Evaluation of Retrieval Augmented Generation},
  journal = {arXiv preprint arXiv:2309.15217},
  year    = {2023},
  url     = {https://arxiv.org/abs/2309.15217},
  urldate = {2025-12-31}
}

@inproceedings{ragas_eacl2024,
  author    = {Es, Shahul and James, Jithin and Espinosa-Anke, Luis and Schockaert, Steven},
  title     = {{RAGAS}: Automated Evaluation of Retrieval Augmented Generation},
  booktitle = {Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations},
  year      = {2024},
  pages     = {150--158},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.eacl-demo.16/},
  doi       = {10.18653/v1/2024.eacl-demo.16},
  urldate   = {2025-12-31}
}

@inproceedings{ares_naacl2024,
  author    = {Saad-Falcon, Jon and Khattab, Omar and Potts, Christopher and Zaharia, Matei},
  title     = {{ARES}: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems},
  booktitle = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  year      = {2024},
  month     = jun,
  address   = {Mexico City, Mexico},
  publisher = {Association for Computational Linguistics},
  pages     = {338--354},
  doi       = {10.18653/v1/2024.naacl-long.20},
  url       = {https://aclanthology.org/2024.naacl-long.20/},
  urldate   = {2025-12-31}
}

% ============================================================
% Chapter 11 (Ethics) — bibliography additions
% Append to your master references.bib (biblatex + biber).
% ============================================================

@online{nist_ai_rmf_100_1,
  title   = {Artificial Intelligence Risk Management Framework (AI RMF 1.0)},
  author  = {{National Institute of Standards and Technology}},
  year    = {2023},
  number  = {NIST AI 100-1},
  url     = {https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf},
  urldate = {2025-12-31}
}

@online{nist_ai_rmf_site,
  title   = {AI Risk Management Framework (AI RMF)},
  author  = {{National Institute of Standards and Technology}},
  url     = {https://www.nist.gov/itl/ai-risk-management-framework},
  urldate = {2025-12-31}
}

@online{nist_ai_600_1_genai,
  title   = {Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile},
  author  = {{National Institute of Standards and Technology}},
  year    = {2024},
  number  = {NIST AI 600-1},
  url     = {https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf},
  urldate = {2025-12-31}
}

@online{eu_ai_act_policy_page,
  title   = {AI Act: Regulatory Framework on Artificial Intelligence},
  author  = {{European Commission}},
  url     = {https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai},
  urldate = {2025-12-31}
}

@inproceedings{mitchell_model_cards,
  title     = {Model Cards for Model Reporting},
  author    = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT*)},
  year      = {2019},
  doi       = {10.1145/3287560.3287596},
  url       = {https://dl.acm.org/doi/10.1145/3287560.3287596},
  urldate   = {2025-12-31}
}

@article{gebru_datasheets,
  title   = {Datasheets for Datasets},
  author  = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daum{\'e} III, Hal and Crawford, Kate},
  journal = {Communications of the ACM},
  year    = {2021},
  doi     = {10.1145/3458723},
  url     = {https://dl.acm.org/doi/10.1145/3458723},
  urldate = {2025-12-31}
}

@online{iso_42001,
  title   = {ISO/IEC 42001:2023 --- Artificial Intelligence Management System},
  author  = {{International Organization for Standardization}},
  year    = {2023},
  url     = {https://www.iso.org/standard/42001.html},
  urldate = {2025-12-31}
}

@online{oecd_ai_principles,
  title   = {OECD AI Principles},
  author  = {{OECD}},
  year    = {2019},
  url     = {https://www.oecd.org/en/topics/ai-principles.html},
  urldate = {2025-12-31}
}

% ======================================================================
% Chapter 1 (Introduction) — Additional citations from PDF
% ======================================================================

@inproceedings{holtzman2020curious,
  author    = {Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
  title     = {The Curious Case of Neural Text Degeneration},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2020},
  url       = {https://arxiv.org/abs/1904.09751}
}

@article{liu2023promptSurvey,
  author  = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  title   = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
  journal = {ACM Computing Surveys},
  volume  = {55},
  number  = {9},
  pages   = {1--35},
  year    = {2023},
  note    = {arXiv:2107.13586},
  url     = {https://doi.org/10.1145/3560815}
}

@misc{edge2025llmops,
  title        = {LLMOps Unpacked: The Operational Complexities of LLMs},
  author       = {Tryolabs Engineering Team},
  howpublished = {Edge AI and Vision Alliance Blog},
  month        = {3},
  year         = {2025},
  url          = {https://www.edge-ai-vision.com/2025/03/llmops-unpacked-the-operational-complexities-of-llms/}
}

@misc{assemblyAI2023decoding,
  title        = {Decoding Strategies: How LLMs Choose The Next Word},
  author       = {AssemblyAI},
  howpublished = {AssemblyAI Blog},
  month        = {5},
  year         = {2023},
  url          = {https://www.assemblyai.com/blog/decoding-strategies-how-llms-choose-the-next-word}
}

@misc{jaeger_tracing,
  title        = {Jaeger: Open Source, End-to-End Distributed Tracing},
  howpublished = {\url{https://www.jaegertracing.io/}},
  note         = {Accessed: 2024-06-10}
}

% =========================================================
% Chapter 8 additional citations (BibLaTeX)
% =========================================================

@article{Dean2013TailAtScale,
  author  = {Dean, Jeffrey and Barroso, Luiz Andr{\'e}},
  title   = {The Tail at Scale},
  journal = {Communications of the ACM},
  year    = {2013},
  volume  = {56},
  number  = {2},
  pages   = {74--80},
  doi     = {10.1145/2408776.2408794}
}

@book{Kleppmann2017DDIA,
  author    = {Kleppmann, Martin},
  title     = {Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems},
  publisher = {O'Reilly Media},
  year      = {2017},
  isbn      = {978-1449373320}
}

@article{Liu2024LostInTheMiddle,
  author  = {Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  title   = {Lost in the Middle: How Language Models Use Long Contexts},
  journal = {Transactions of the Association for Computational Linguistics},
  year    = {2024},
  volume  = {12},
  pages   = {157--173},
  doi     = {10.1162/tacl_a_00638}
}

@online{OWASP2024LLMTop10,
  author  = {{OWASP Foundation}},
  title   = {OWASP Top 10 for Large Language Model Applications, Version 1.1},
  year    = {2024},
  url     = {https://owasp.org/www-project-top-10-for-large-language-model-applications/},
  urldate = {2026-01-05}
}

@book{Wooldridge2009MultiAgent,
  author    = {Wooldridge, Michael},
  title     = {An Introduction to MultiAgent Systems},
  edition   = {2},
  publisher = {John Wiley \& Sons},
  year      = {2009},
  isbn      = {978-0470519462}
}

@article{Yao2022ReAct,
  author  = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  title   = {ReAct: Synergizing Reasoning and Acting in Language Models},
  year    = {2022},
  journal = {arXiv preprint arXiv:2210.03629},
  doi     = {10.48550/arXiv.2210.03629}
}

@article{Schick2023Toolformer,
  author  = {Schick, Timo and Dwivedi-Yu, Jane and Dess{\`i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  title   = {Toolformer: Language Models Can Teach Themselves to Use Tools},
  year    = {2023},
  journal = {arXiv preprint arXiv:2302.04761},
  doi     = {10.48550/arXiv.2302.04761}
}

@article{Shen2023HuggingGPT,
  author  = {Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  title   = {HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face},
  year    = {2023},
  journal = {arXiv preprint arXiv:2303.17580},
  doi     = {10.48550/arXiv.2303.17580}
}

@article{Wu2023AutoGen,
  author  = {Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Li, Beibin and Zhu, Erkang and Jiang, Li and Zhang, Xiaoyun and Zhang, Shaokun and Liu, Jiale and Awadallah, Ahmed Hassan and White, Ryen W. and Burger, Doug and Wang, Chi},
  title   = {AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation},
  year    = {2023},
  journal = {arXiv preprint arXiv:2308.08155},
  doi     = {10.48550/arXiv.2308.08155}
}

@article{Yao2023TreeOfThoughts,
  author  = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L. and Cao, Yuan and Narasimhan, Karthik},
  title   = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  year    = {2023},
  journal = {arXiv preprint arXiv:2305.10601},
  doi     = {10.48550/arXiv.2305.10601}
}

@article{Shinn2023Reflexion,
  author  = {Shinn, Noah and Cassano, Federico and Berman, Edward and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  title   = {Reflexion: Language Agents with Verbal Reinforcement Learning},
  year    = {2023},
  journal = {arXiv preprint arXiv:2303.11366},
  doi     = {10.48550/arXiv.2303.11366}
}

@article{Park2023GenerativeAgents,
  author  = {Park, Joon Sung and O'Brien, Joseph C. and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
  title   = {Generative Agents: Interactive Simulacra of Human Behavior},
  year    = {2023},
  journal = {arXiv preprint arXiv:2304.03442},
  doi     = {10.48550/arXiv.2304.03442}
}

@article{Greshake2023IndirectPromptInjection,
  author  = {Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Fritz, Mario and Endres, Christoph and Holz, Thorsten},
  title   = {Not What You{\textquoteright}ve Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection},
  year    = {2023},
  journal = {arXiv preprint arXiv:2302.12173},
  doi     = {10.48550/arXiv.2302.12173}
}

@article{Liu2023AgentBench,
  author  = {Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and Zhang, Shudan and Deng, Xiang and Zeng, Aohan and Du, Zhengxiao and Zhang, Chenhui and Shen, Sheng and Zhang, Tianjun and Su, Yu and Sun, Huan and Huang, Minlie and Dong, Yuxiao and Tang, Jie},
  title   = {AgentBench: Evaluating LLMs as Agents},
  year    = {2023},
  journal = {arXiv preprint arXiv:2308.03688},
  doi     = {10.48550/arXiv.2308.03688}
}

@article{Zhou2023WebArena,
  author  = {Zhou, Shuyan and Xu, Frank F. and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Ou, Tianyue and Bisk, Yonatan and Fried, Daniel and Alon, Uri and Neubig, Graham},
  title   = {WebArena: A Realistic Web Environment for Building Autonomous Agents},
  year    = {2023},
  journal = {arXiv preprint arXiv:2307.13854},
  doi     = {10.48550/arXiv.2307.13854}
}

@article{Qin2023ToolLLM,
  author  = {Qin, Yujia and Liang, Shihao and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and Zhao, Sihan and Hong, Lauren and Tian, Runchu and Xie, Ruobing and Zhou, Jie and Gerstein, Mark and Li, Dahai and Liu, Zhiyuan and Sun, Maosong},
  title   = {ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs},
  year    = {2023},
  journal = {arXiv preprint arXiv:2307.16789},
  doi     = {10.48550/arXiv.2307.16789}
}

@online{OpenTelemetryTraces,
  author  = {{OpenTelemetry Project}},
  title   = {OpenTelemetry Specification: Trace},
  year    = {2025},
  url     = {https://opentelemetry.io/docs/specs/otel/trace/},
  urldate = {2026-01-05}
}

@online{OWASP2025LLMTop10,
  author  = {{OWASP Foundation}},
  title   = {OWASP Top 10 for Large Language Model Applications (v2025)},
  year    = {2024},
  url     = {https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-v2025.pdf},
  urldate = {2026-01-05}
}

@inproceedings{ribeiro2020checklist,
  title     = {Beyond Accuracy: Behavioral Testing of {NLP} Models with {CheckList}},
  author    = {Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)},
  pages     = {4902--4912},
  year      = {2020},
  doi       = {10.18653/v1/2020.acl-main.442},
  url       = {https://aclanthology.org/2020.acl-main.442/}
}

@techreport{chen1998metamorphic,
  title       = {Metamorphic Testing: A New Approach for Generating Next Test Cases},
  author      = {Chen, T. Y. and Cheung, S. C. and Yiu, S. M.},
  institution = {Department of Computer Science, Hong Kong University of Science and Technology},
  number      = {HKUST-CS98-01},
  year        = {1998},
  url         = {https://www.cse.ust.hk/faculty/scc/publ/CS98-01-metamorphictesting.pdf}
}

@inproceedings{claessen2000quickcheck,
  title     = {QuickCheck: A Lightweight Tool for Random Testing of {Haskell} Programs},
  author    = {Claessen, Koen and Hughes, John},
  booktitle = {Proceedings of the 5th ACM SIGPLAN International Conference on Functional Programming (ICFP)},
  year      = {2000},
  doi       = {10.1145/351240.351266},
  url       = {https://dl.acm.org/doi/10.1145/351240.351266}
}

@book{efron1994bootstrap,
  title     = {An Introduction to the Bootstrap},
  author    = {Efron, Bradley and Tibshirani, Robert J.},
  year      = {1994},
  publisher = {Chapman and Hall/CRC},
  doi       = {10.1201/9780429246593},
  url       = {https://www.taylorfrancis.com/books/mono/10.1201/9780429246593/}
}

@article{cohen1960kappa,
  title   = {A Coefficient of Agreement for Nominal Scales},
  author  = {Cohen, Jacob},
  journal = {Educational and Psychological Measurement},
  volume  = {20},
  number  = {1},
  pages   = {37--46},
  year    = {1960},
  doi     = {10.1177/001316446002000104}
}

@article{fleiss1971kappa,
  title   = {Measuring Nominal Scale Agreement among Many Raters},
  author  = {Fleiss, Joseph L.},
  journal = {Psychological Bulletin},
  volume  = {76},
  number  = {5},
  pages   = {378--382},
  year    = {1971},
  doi     = {10.1037/h0031619}
}

@article{basiri2016chaos,
  title   = {Chaos Engineering},
  author  = {Basiri, Ali and Behnam, Niosha and de Rooij, Ruud and Hochstein, Lorin and Kosewski, Lukas and Reynolds, Justin and Rosenthal, Casey},
  journal = {IEEE Software},
  volume  = {33},
  number  = {3},
  pages   = {35--41},
  year    = {2016},
  doi     = {10.1109/MS.2016.60},
  url     = {https://arxiv.org/abs/1702.05843}
}

@inproceedings{liu2023geval,
  title     = {G-Eval: {NLG} Evaluation using {Gpt-4} with Better Human Alignment},
  author    = {Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages     = {2511--2522},
  year      = {2023},
  doi       = {10.18653/v1/2023.emnlp-main.153},
  url       = {https://aclanthology.org/2023.emnlp-main.153/}
}

@misc{zheng2023mtbench,
  title         = {Judging {LLM}-as-a-Judge with {MT}-Bench and Chatbot Arena},
  author        = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P. and Zhang, Hao and Gonzalez, Joseph E. and Stoica, Ion},
  year          = {2023},
  eprint        = {2306.05685},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2306.05685}
}

@misc{saito2023verbositybias,
  title         = {Verbosity Bias in Preference Labeling by Large Language Models},
  author        = {Saito, Keita and Wachi, Akifumi and Wataoka, Koki and Akimoto, Youhei},
  year          = {2023},
  eprint        = {2310.10076},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2310.10076}
}
