% Part III verso page introduction

\noindent\textbf{Part III: Optimization, Retrieval, and Agents}

Part III delves into advanced techniques for improving performance, integrating external knowledge, and orchestrating complex multi-agent workflows. Chapter~\ref{ch:performance} covers optimization strategies including quantization, distillation, and inference engine selection that directly impact latency and cost. Chapter~\ref{ch:rag} provides comprehensive coverage of retrieval-augmented generation, from embedding models and vector databases to chunking strategies and reranking---techniques that ground LLM outputs in verifiable sources. Chapter~\ref{ch:multiagent} explores multi-agent architectures, coordination patterns, and orchestration frameworks that enable sophisticated LLM applications.

These chapters address the technical depth required to build high-performance, knowledge-grounded, and composable LLM systems. Throughout, \ishtar{} serves as a reference implementation, showing how optimization, retrieval, and agent coordination combine in a production system.

