% Part I verso page introduction

\noindent\textbf{Part I: Foundations of LLMOps}

The first part of this book establishes the conceptual and practical foundations necessary for understanding and implementing Large Language Model Operations. We begin by introducing the discipline of LLMOps and its relationship to traditional MLOps, using the \ishtar{} AI case study as a concrete reference throughout. Chapter~\ref{ch:intro} provides the motivation and context for why LLMOps represents a distinct operational discipline, while Chapter~\ref{ch:llmops-fundamentals} formalizes core concepts including prompt engineering, retrieval-augmented generation, and evaluation frameworks. Chapter~\ref{ch:infra} completes the foundation by covering infrastructure design, hardware selection, and environment setup---the bedrock upon which all LLM systems are built.

Together, these three chapters equip readers with the theoretical understanding and practical knowledge needed to approach the operational challenges covered in subsequent parts. The \ishtar{} case study threads through each chapter, demonstrating how foundational principles translate into real-world implementation decisions.

